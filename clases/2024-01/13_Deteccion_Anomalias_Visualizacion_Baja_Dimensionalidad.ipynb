{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 13: Detecci√≥n de Anomal√≠as y Visualizaci√≥n en Baja Dimensionalidad\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objetivos de la Clase\n",
    "\n",
    "- Entender qu√© es un outlier y explorar distintas t√©ncicas para encontrarlos.\n",
    "- Explorar t√©cnicas para visualizar datos en baja dimensionalidad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecci√≥n y manejo de Anomal√≠as\n",
    "\n",
    "> **Pregunta**: ¬øQu√© es una anomal√≠a?\n",
    "\n",
    "Una anomal√≠a (*outlier* en ingles) es un dato significativamente distinto a los dem√°s. Se puede considerar como una observaci√≥n cuya desviaci√≥n del conjunto de datos permite establecer la hip√≥tesis, de que su generaci√≥n fue obtenida por un mecanismo distinto al principal en la modelaci√≥n de un fen√≥meno.\n",
    "\n",
    "![Outlier](../../recursos/2023-01/16-Detecci√≥n-anomalias/outliers.gif)\n",
    "\n",
    "> **Pregunta**: ¬øPor qu√© deber√≠a preocuparme por estos valores?\n",
    "\n",
    "Las anomal√≠as contienen por tanto informaci√≥n sobre caracter√≠sticas anormales de las entidades y esquemas que impactan el proceso generativo de los datos. Reconocer estas observaciones permite:\n",
    "- Desde el punto de vista te√≥rico, mejorar el entendimiento de los problemas modelados. \n",
    "- Desde el punto de vista pr√°ctico, permite mejorar procesos de adquisici√≥n de datos y presici√≥n de modelos.\n",
    "\n",
    "\n",
    "Antes de continuar, es necesario hacer una distinci√≥n entre t√©rminos:\n",
    "\n",
    "- **Detecci√≥n de Outliers** : Detectamos anomal√≠as sobre los datos que estamos analizando o sobre los datos de entrenamiento del modelo.\n",
    "\n",
    "- **Novelty Detection**: Cuando detectamos outliers sobre **datos nuevos**.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Outliers\n",
    "\n",
    "- **Univariados**: Solo en una caracter√≠stica de los datos.\n",
    "- **Multivariados**: Outlier al combinar m√°s de una caracter√≠stica de los datos.\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origen de los Outliers\n",
    "\n",
    "\n",
    "> **Pregunta ‚ùì**: ¬øCu√°les son las posibles fuentes de Outliers?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Errores al transcribir los Datos.\n",
    "- Errores de Medici√≥n.\n",
    "- Errores Experimentales.\n",
    "- Errores del preprocesamiento.\n",
    "- Al extraer o mezclar datos que no son compatibles entre si.\n",
    "- Naturales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset de Hoy: Wine Quality üç∑\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/wine.jpg\" style=\"width: 50%;\">\n",
    "</div>\n",
    "\n",
    "<center> Fuente de la imagen: https://www.baysidegroup.com.au/blog/could-native-grapes-be-the-future-of-australian-wine/</center>\n",
    "\n",
    "Wine Quality es un dataset de caracter√≠sticas que describen vinos portugeses de la variedad \"Vinho Verde\".\n",
    "\n",
    "Atributos:\n",
    "\n",
    "    1 - fixed acidity\n",
    "    2 - volatile acidity\n",
    "    3 - citric acid\n",
    "    4 - residual sugar\n",
    "    5 - chlorides\n",
    "    6 - free sulfur dioxide\n",
    "    7 - total sulfur dioxide\n",
    "    8 - density\n",
    "    9 - pH\n",
    "    10 - sulphates\n",
    "    11 - alcohol\n",
    "    \n",
    "Output: Calidad subjetiva del vino.\n",
    "\n",
    "    12 - quality (score between 0 and 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "df = pd.read_csv(\"../../recursos/2023-01/16-Detecci√≥n-anomalias/wineQualityReds.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    fig = px.histogram(df, x=col, marginal=\"box\", title = 'Histogram of ' + col)\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todos de Manejo de Anomal√≠as Univariados\n",
    "\n",
    "\n",
    "#### Desviaci√≥n Est√°ndar\n",
    "\n",
    "Si se estima que la variable a estudiar se distribuye de manera normal, entonces el 95% de los datos se encuentra a 2 desviaciones est√°ndar de la media, mientras que el 99.7% se encuentra dentro de 3 desviaciones est√°ndar. Bas√°ndose en esto, se puede considerar que cualquier punto fuera de 3 desviaciones est√°ndar de la media como candidato a anomal√≠a. Una forma m√°s flexible de estimar anomal√≠as usando el principio de normalidad, es por medio de z-scores. \n",
    "\n",
    "\n",
    "$$\\text{z-score} = \\frac{x_i - \\overline{x}}{s}$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/norm.png\" style=\"width: 75%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Create distplot with curve_type set to 'normal'\n",
    "fig = ff.create_distplot(\n",
    "    [df[\"fixed.acidity\"].values], [\"fixed.acidity\"], curve_type=\"normal\", show_rug=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(df[\"fixed.acidity\"])\n",
    "z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos los zscores al df\n",
    "df[\"fixed.acidity_zscores\"] = z_scores\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fixed.acidity_zscores\"].abs() > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos un booleano por cada fila que indica si la observaci√≥n est√°\n",
    "# a 3 o m√°s distribuciones estandar entonces es booleano.\n",
    "df[\"fixed.acidity_outlier\"] = df[\"fixed.acidity_zscores\"].abs() > 3\n",
    "\n",
    "df[[\"fixed.acidity\", \"fixed.acidity_zscores\", \"fixed.acidity_outlier\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    df[\"fixed.acidity_outlier\"], # condicion: fixed.acidity_outlier == True\n",
    "    [\"fixed.acidity\", \"fixed.acidity_zscores\", \"fixed.acidity_outlier\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"fixed.acidity\", color=\"fixed.acidity_outlier\")\n",
    "fig.update_layout(showlegend=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se va a estudiar una columna con ouliers mediante este m√©todo, es coveniente hacer un **test de normalidad**. Si la variable no cumple con la hip√≥tesis, es posible preprocesarla usando el m√©todo de **box-cox**, **Yeo-Johnson** o **Inter Quantilico**. Se recomienda este √∫ltimo por ser robusto a outliers. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### IQR: Rango Intercuartilico\n",
    "\n",
    "El rango intercuart√≠lico (**IQR**) se utiliza para medir la dispersi√≥n de los datos. \n",
    "Para obtenerlo: \n",
    "\n",
    "Los datos se separan en 4 grupo de (casi) igual tama√±o.\n",
    "El IQR se calcula como la diferencia entre el primer cuartil $Q1$ (25%) y el tercero $Q3$ (75%) : $IQR = Q3 - Q1$.\n",
    "\n",
    "<div align='center'>\n",
    "    <img src=\"https://miro.medium.com/max/9000/1*2c21SkzJMf3frPXPAR_gZA.png\" style=\"width: 50%;\">\n",
    "    <p> \n",
    "        Fuente: \n",
    "        <a href='https://www.kdnuggets.com/2019/11/understanding-boxplots.html'>Understanding Boxplots\n",
    "        </a> \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total.sulfur.dioxide\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, \"total.sulfur.dioxide\", marginal=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df[\"total.sulfur.dioxide\"].describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = desc[\"75%\"] - desc[\"25%\"]\n",
    "iqr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, los valores que est√©n en $25\\% - (IQR * 1.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cota_inf = desc[\"25%\"] - iqr * 1.5\n",
    "cota_inf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y los valores que est√©n sobre $75\\% + (IQR * 1.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cota_sup = desc[\"75%\"] + iqr * 1.5\n",
    "cota_sup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pueden ser considerados como outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total.sulfur.dioxide_outlier\"] = (\n",
    "    df[\"total.sulfur.dioxide\"] > cota_sup) | (\n",
    "    df[\"total.sulfur.dioxide\"] < cota_inf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig1 = px.box(df, x=\"total.sulfur.dioxide\", height=200)\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.histogram(\n",
    "    df,\n",
    "    x=\"total.sulfur.dioxide\",\n",
    "    color=\"total.sulfur.dioxide_outlier\",\n",
    "    title=\"total.sulfur.dioxide<br><sup>Rojo = outlier</sup>\",\n",
    ")\n",
    "fig2.update_layout(showlegend=False)\n",
    "fig2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gr√°fico de caja, vemos que los outliers est√°n sobre y bajo las lineas rectas, cada una representa Q1 - 1.5 x IQR (linea inferior) y Q3 + 1.5 x IQR (linea superior) Los valores dentro de la caja corresponden al IQR y la linea central es la mediana de los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pregunta:** ¬øPor qu√© 1.5 y no otro n√∫mero?\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/iqr_origen.png\" style=\"width: 50%;\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducci√≥n de Dimensionalidad para la Visualizaci√≥n \n",
    "\n",
    "Como hemos visto en las clases anteriores, todos las observaciones se componen de muchas variables/caracter√≠sticas distintas. Mientras m√°s caracter√≠sticas se tengan, m√°s complejo se torna el an√°lisis exploratorio de datos, la detecci√≥n de outliers y la creaci√≥n de modelos predictivos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Por lo tanto, ser√≠a de mucha utilidad contar con mecanismos para reducir la cantidad de caracter√≠sticas. Existen 2 enfoques: \n",
    "\n",
    "- **Selecci√≥n de Atributos Relevantes**\n",
    "- **Reducci√≥n de Dimensionalidad.**\n",
    "\n",
    "Ambos ser√°n vistos con mayor profundidad m√°s adelante. \n",
    "\n",
    "Sin embargo, existe un par de m√©todos de reducci√≥n de dimensionalidad que nos pueden ser particularmente √∫tiles para la tarea que estamos resolviendo en este momento (detecci√≥n de outliers) y en general, para crear una idea de como se distribuyen los datos al considerar todas las caracter√≠sticas.\n",
    "\n",
    "\n",
    "Estos son los **m√©todos de reducci√≥n de dimensionalidad para visualizaci√≥n**. Estas son t√©cnicas que nos permiten representar cada observaci√≥n (un vector de alta dimensionalidad) en un vector de dos o tres dimensiones (mucho m√°s sencillo para graficar).\n",
    "\n",
    "\n",
    "**Par√©ntesis: Manifold learning**  \n",
    "\n",
    "\n",
    "> Manifold learning es un enfoque para la reducci√≥n de dimensionalidad no lineal. Los algoritmos para esta tarea se basan en la idea de que la dimensionalidad de muchos conjuntos de datos es solo artificialmente alta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "\n",
    "La idea detr√°s de este m√©todo es proveer un m√©todo efectivo de reducci√≥n de dimensionalidad para visualizar un dataset complejo. El objetivo es conservar la mayor parte de la informaci√≥n en la dimensi√≥n baja a la vez que permita visualizar clusters y estructura general de los datos.\n",
    "\n",
    "Este m√©todo conserva la localidad de las observaciones: Es decir, las observaciones similares queden en vectores cercanos y observaciones distintas en vectores lejanos (cercanos y lejanos en funci√≥n de sus distancias).\n",
    "\n",
    "\n",
    "Sin embargo, el m√©todo posee un par de desventajas:\n",
    "\n",
    "- Es computacionalmente caro. Puede tomar horas transformar m√°s de un millon de datos.\n",
    "- Es estoc√°stico: diferentes ejecuciones entregan distintas proyecciones.\n",
    "- Las relaciones entre distancias globales no se preservan correctamente.\n",
    "\n",
    "> **Nota**: Es importante tener a la misma escala todos los datos.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://miro.medium.com/max/800/1*lKLB_1aghhnxQjMQziEyGQ.gif\" style=\"width: 50%;\">\n",
    "</div>\n",
    "\n",
    "<center>Fuente de la animaci√≥n: https://www.oreilly.com/content/an-illustrated-introduction-to-the-t-sne-algorithm/</center>\n",
    "\n",
    "\n",
    "No veremos la implementaci√≥n de este m√©todo en clases, pero pueden encontrar una muy buena referencia en el siguiente video: https://www.youtube.com/watch?v=NEaUSP4YerM\n",
    "\n",
    "Ver tambi√©n: **https://projector.tensorflow.org/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(\n",
    "    columns=[\n",
    "        \"quality\",\n",
    "        \"fixed.acidity_zscores\",\n",
    "        \"fixed.acidity_outlier\",\n",
    "        \"total.sulfur.dioxide_outlier\",\n",
    "    ]\n",
    ")\n",
    "quality = df.loc[:, [\"quality\"]]\n",
    "\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Notar que hacemos un escalamiento previo!!\n",
    "scaled_features = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "# Creamos una instancia de tsne\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# Transformamos los datos\n",
    "wine_features_tsne_embedded = tsne.fit_transform(scaled_features)\n",
    "wine_features_tsne_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noten que guardamos la transformaci√≥n en df y no en features.\n",
    "df[\"x_tsne\"] = wine_features_tsne_embedded[:, 0]\n",
    "df[\"y_tsne\"] = wine_features_tsne_embedded[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"pH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"alcohol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"residual.sugar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"fixed.acidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probamos el criterio de outliers z-score\n",
    "px.scatter(df, x=\"x_tsne\", y=\"y_tsne\", color=\"fixed.acidity_outlier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Manifold Approximation and Projection (UMAP)\n",
    "\n",
    "Relativamente novedoso m√©todo de reducci√≥n de dimensionalidad. Puede ser usado tanto para visualizaci√≥n como para reducci√≥n de dimensionalidad para modelos predictivos. \n",
    "\n",
    "Presenta varias mejoras que con respecto a TSNE.  \n",
    "\n",
    "- Es m√°s r√°pido y acepta una mayor cantidad de datos. \n",
    "- Conserva las distancias globales entre puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay que instalarlo aparte.\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Notar que hacemos un escalamiento previo!!\n",
    "scaled_features = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "umap = umap.UMAP()\n",
    "\n",
    "wine_features_umap_embedded = umap.fit_transform(scaled_features)\n",
    "wine_features_umap_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noten que guardamos la transformaci√≥n en df y no en features.\n",
    "df[\"x_umap\"] = wine_features_umap_embedded[:, 0]\n",
    "df[\"y_umap\"] = wine_features_umap_embedded[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig1 = px.scatter(\n",
    "    df,\n",
    "    x=\"x_umap\",\n",
    "    y=\"y_umap\",\n",
    ")\n",
    "\n",
    "fig2 = px.scatter(\n",
    "    df,\n",
    "    x=\"x_tsne\",\n",
    "    y=\"y_tsne\",\n",
    ")\n",
    "\n",
    "# izquierda: UMAP\n",
    "# derecha: TSNE\n",
    "fig = (\n",
    "    make_subplots(rows=1, cols=2)\n",
    "    .add_trace(fig1.data[0], row=1, col=1)\n",
    "    .add_trace(fig2.data[0], row=1, col=2)\n",
    "    .update_layout(height=400, title_text=\"Comparaci√≥n UMAP - TSNE\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df,\n",
    "    x=\"x_umap\",\n",
    "    y=\"y_umap\",\n",
    "    color=\"quality\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=\"fixed.acidity_outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=\"fixed.acidity\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pregunta:** ¬øSon suficientes los detectores de outliers sobre sola una variable?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todos de Manejo de Outliers Multivariados\n",
    "\n",
    "\n",
    "Este tipo de m√©todos permiten encontrar outliers considerando no solo un atributo en particular, si no que todos los atributos al mismo tiempo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par√©ntesis: Clustering\n",
    "\n",
    "\n",
    "**El Clustering es la tarea de agrupar distintas observaciones seg√∫n su similitud.**\n",
    "\n",
    "Es de tipo no-supervisado (no requiere etiquetas para entrenar).\n",
    "\n",
    "![](./resources/clustering.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBScan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBscan es un algoritmo de clustering basado en densidad. Su funcionamiento se basa en clasificar los datos en tres categor√≠as:\n",
    "\n",
    "- **Core point**: Es un punto que contiene un n√∫mero minimo de vecinos cerca de un vecindario (esfera de radio …õ)\n",
    "\n",
    "- **Border point**: Es un punto que no es core, pero que es alcanzable por un Core Point. Es decir, existe un camino entre el Core Point y este.\n",
    "\n",
    "- **Outlier**: Es un punto que no es core point y a la vez, que no tiene un camino entre un Core Point u Border Point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/dbscan.png\" style=\"width: 50%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# El par√°metro eps indicar√° el tama√±o de la esfera y por tanto, la cantidad de outliers\n",
    "# Mientras menor sea el tama√±o de eps, mayor la cantidad de outliers\n",
    "clustering = DBSCAN(eps=0.3, min_samples=3).fit(scaled_features)\n",
    "\n",
    "db_scan_labels = clustering.labels_\n",
    "\n",
    "db_scan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_scan_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: Los labels de los outliers son -1\n",
    "df[db_scan_labels == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es m√°s sencillo visualizar los outliers con color=db_scan_labels == -1\n",
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=db_scan_labels == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=db_scan_labels.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Volvemos a hacer lo mismo pero con las dimensiones de UMAP\n",
    "clustering_projections = DBSCAN(eps=0.3, min_samples=3).fit(wine_features_umap_embedded)\n",
    "\n",
    "db_scan_labels = clustering_projections.labels_\n",
    "\n",
    "db_scan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_features_umap_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=db_scan_labels.astype(str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todos Espec√≠ficos Provistos por Scikit-Learn\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/outlier_methods_sklearn.png\" style=\"width: 50%;\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "\n",
    "El concepto subyacente de Isolation Forest es que las anomal√≠as son datos que son pocos y diferentes, y por lo tanto, **m√°s f√°ciles de aislar** que los datos normales. Isolar se refiere al proceso de separar un punto de datos del resto del conjunto de datos.\n",
    "\n",
    "#### ¬øC√≥mo funciona?\n",
    "\n",
    "1. Construcci√≥n de √Årboles de Aislamiento: Isolation Forest construye m√∫ltiples √°rboles de decisi√≥n, llamados √°rboles de aislamiento, para aislar cada muestra de datos. Para cada √°rbol, el proceso es como sigue:\n",
    "    - **Seleccionar aleatoriamente una variable** y luego selecciona un valor aleatorio de corte entre el m√≠nimo y m√°ximo valor de la caracter√≠stica seleccionada.\n",
    "    - **Dividir el conjunto de datos en dos subconjuntos**: uno con valores menores que el valor de corte y otro con valores mayores o iguales.\n",
    "    - **Repetir este proceso** recursivamente en cada subconjunto hasta que todos los datos han sido aislados o se alcanza un l√≠mite predeterminado en la profundidad del √°rbol.\n",
    "2. Propiedad de Aislamiento: En teor√≠a, las anomal√≠as, al ser pocos y distintos, **requieren menos divisiones** aleatorias para ser aislados en comparaci√≥n con los puntos de datos normales. Por lo tanto, los puntos de datos que tienen caminos cortos en los √°rboles son m√°s propensos a ser anomal√≠as.\n",
    "\n",
    "#### C√°lculo de puntuaci√≥n de Anomal√≠a\n",
    "\n",
    "Una vez construidos los √°rboles, Isolation Forest eval√∫a la anormalidad de los datos utilizando una puntuaci√≥n de anomal√≠a basada en la **longitud del camino promedio** de un punto de datos en los √°rboles de aislamiento.\n",
    "**Cuanto m√°s corto es el camino promedio de un punto de datos, m√°s alta es la puntuaci√≥n de anomal√≠a**, lo que indica una mayor probabilidad de ser una anomal√≠a.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../../recursos/2023-01/16-Detecci√≥n-anomalias/itree.png\" style=\"width: 50%;\">\n",
    "</div>\n",
    "    \n",
    "<center>Fuente:https://betterprogramming.pub/anomaly-detection-with-isolation-forest-e41f1f55cc6</center>\n",
    "\n",
    "#### Ventajas de Isolation Forest\n",
    "- **Eficiencia**: Es eficaz en grandes conjuntos de datos y con una alta dimensionalidad de datos.\n",
    "- **No necesita normalizaci√≥n**: A diferencia de otros m√©todos que requieren normalizaci√≥n de datos, Isolation Forest no necesita normalizar los datos porque el m√©todo de partici√≥n es independiente de la distribuci√≥n.\n",
    "- **Escalabilidad y Facilidad de Implementaci√≥n**: Es relativamente f√°cil de implementar y escalar en comparaci√≥n con otros m√©todos de detecci√≥n de anomal√≠as.\n",
    "\n",
    "\n",
    "<center>Trafico web a trav√©s del tiempo<center/>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Anomalous_Web_Traffic.png\" style=\"width: 60%;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isf = IsolationForest(n_estimators=20, random_state=42)\n",
    "outliers = isf.fit_predict(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"x_umap\", y=\"y_umap\", color=outliers.astype(str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Novelty Detection\n",
    "\n",
    "Ya que tenemos el modelo entrenado, podemos aplicarlo para clasificar una nueva observaci√≥n (fuera del conjunto de entrenamiento) como outlier o no. Podemos lograr esto a trav√©s del m√©todo `.predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = scaled_features[100, :].copy() # obtenemos una fila\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isf.predict([row]) # 1: no es outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[0] *= -100 # cambiar feature 0  * -1000 \n",
    "row[5] *= 500 # cambiar feature 5 * 500\n",
    "row[10] *= 999 # cambiar feature 10 * 999\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isf.predict([row]) # -1: es outlier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.717px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
