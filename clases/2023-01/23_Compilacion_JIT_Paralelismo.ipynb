{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958072d5-97d3-4e0a-bb65-a52954f1401e",
   "metadata": {},
   "source": [
    "# Clase 23: Compilación, Paralelismo y Computación Distribuida\n",
    "\n",
    "**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n",
    "\n",
    "**Profesor: Pablo Badilla**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7701ae9-abcd-4fee-94fd-100202a99ab7",
   "metadata": {},
   "source": [
    "## Objetivos de la clase:\n",
    "\n",
    "- Aprender a optimizar código a través de `JIT`.\n",
    "- Comprender el paralelismo de tareas.\n",
    "- Aprender a paralelizar tareas por medio de funciones en `Joblib`\n",
    "- Comprender la idea general de computación distribuida.\n",
    "- Analizar las opciones para computación distribuida: `Dask`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d64bdcdb",
   "metadata": {},
   "source": [
    "## Motivación\n",
    "\n",
    "El flujo de trabajo en ciencia de datos consta de **numerosas rutinas de carga, procesamiento y visualización**. Lo ideal es que diseñemos estas rutinas de la forma más optima posible con el fin de reducir recursos, tiempos de carga utilizados y sus costos asociados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979e870b",
   "metadata": {},
   "source": [
    "\n",
    "## Lenguajes de Programación\n",
    "\n",
    "El lenguaje de máquina es el conjunto de instrucciones que el hardware es capaz de interpretar y procesar.\n",
    "A través de estas instrucciones podemos lograr que nuestro procesador ejecute distintos tipos de acciones muy básicas. \n",
    "Este conjuntos de lenguajes es comunmente conocido como *lenguaje de bajo nivel*\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/codigo_maquina.png' width=400 />\n",
    "<center/>\n",
    "\n",
    "<center>Por suerte no tenemos que si quiera pensar en esto...</center>\n",
    "    \n",
    "<center> \n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Machine_code#/media/File:W65C816S_Machine_Code_Monitor.jpeg'>Wikipedia </a>\n",
    "</center>\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7e10b3-aeb6-4dd7-bd5d-d1a30d1eb926",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lenguajes Compilados vs Intepretados\n",
    "\n",
    "Existen dos enfoques principales para convertir un código de lenguaje de alto nivel a uno de bajo nivel: que el lenguaje sea **Compilado** o **Interpretado**.\n",
    "\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/tipos_lenguajes.png' width=800 />\n",
    "</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4a2f75a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computación de alto Rendimiento con Python\n",
    "\n",
    "Python es utilizado transversalmente, ya sea en la industria o en la academia. Dentro de sus cualidades se encuentra la portabilidad de código, sintaxis intuitiva, disponibilidad de herramientas y documentación. Sin embargo, al ser un lenguaje interpretado se pierden ciertas características intrínsicas de los lenguajes de bajo nivel como C, C++ y Fortran.\n",
    "\n",
    "En esta y la próxima clase estudiaremos distintas herramientas para mejorar el rendimiento del interprete, como el uso eficiente de objetos base y la aplicación de técnicas de paralelismo y compilación utilizando tanto librerías nativas, como desarrolladas por terceros. \n",
    "\n",
    "\n",
    "> **Pregunta ❓:** ¿Será conveniente programar siempre pensando crear código óptimo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c29f46b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimización del Código\n",
    "\n",
    " Como directriz general, se recomienda llevar el proceso de desarrollo en dos etapas:\n",
    " \n",
    "1. La primera consiste en **generar código correcto, comprensibles y mantenibles**, evitando la sobre-optimización prematura de código. \n",
    "\n",
    "2. Como segunda etapa, se recomienda comenzar con los procesos de **optimización de código**. Esto pues, las herramientas que permiten mejorar los aspectos computacionales, interfieren en la sencillez del código, entorpeciendo los procesos de depuración y mantención. \n",
    "\n",
    "Una vez que las rutinas están implementadas de manera correcta, la mejor manera de enfocar los esfuerzos, pasa por **perfilar** (*profiling*) el código. Esto consiste en encontrar las zonas de código criticas en cuanto a carga computacional. La manera más directa de encontrar estas zonas, es por medio del uso de contadores de tiempo o *timers*.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d674ef72",
   "metadata": {},
   "source": [
    "### Medición del Tiempo de Ejecución ⏰\n",
    "\n",
    "\n",
    "El tiempo de ejecución es el tiempo tomado por algun segemento de código, función en completar su ejecución.\n",
    "\n",
    "En Python, la forma más sencilla de medir el tiempo de ejecución es a través de la librería `time`. El ejemplo siguiente muestra como utilizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import cos, sin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b13ba90a",
   "metadata": {},
   "source": [
    "Definimos un rango de datos a operar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b295a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.1 * i for i in range(100000)]\n",
    "\n",
    "x[0:10]  # veamos los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ee1d307",
   "metadata": {},
   "source": [
    "Luego definimos la función que mediremos. Esta simplemente calcula $(\\sin(val) + \\cos(val)^2)^{1/3}$ y luego retorna su valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(val):\n",
    "    return (sin(val) + cos(val) ** 2) ** (1 / 9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbd24073",
   "metadata": {},
   "source": [
    "Ahora, estudiamos el tiempo de ejecución por medio de la función `process_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiempo inicial\n",
    "t0 = time.process_time()\n",
    "\n",
    "for i in x:\n",
    "    func_1(i)\n",
    "\n",
    "# tiempo final\n",
    "t1 = time.process_time()\n",
    "\n",
    "# el tiempo transcurrido es simplemente el delta entre t1 y t0\n",
    "print(\"Tiempo transcurrido\", t1 - t0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "654e69a7",
   "metadata": {},
   "source": [
    "> **Pregunta ❓:** ¿Si ejecutamos nuevamente la celda anterior, obtendremos los mismos tiempos? ¿Existirá alguna forma más consistente de medir el tiempo de ejecución del código?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5189c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### `timeit`\n",
    "\n",
    "En algunas ocasiones se desea medir el tiempo de ejecución para tareas sencillas, la librería estándar de Python provee el módulo `timeit`. En la práctica, una llamada de `timeit` ejecuta por defecto 10.000.000 el código (variable según cuánto se demore el proceso) y repite 7 veces el experimento. Lluego reporta el tiempo de ejecución promedio.\n",
    "\n",
    "Este puede ser utilizado directamente en la consola interactiva IPython o en notebooks de Jupyter por medio del comando mágico `%timeit` para el caso de una linea de código y `%%timeit` para medir toda la celda. \n",
    "\n",
    "Documentación de `%timeit`: [Timeit Magic en la documentación de Ipython](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19a2f9c2",
   "metadata": {},
   "source": [
    "\n",
    "**Ejemplo**\n",
    "\n",
    "\n",
    "Medimos la eficiencia de la implementación original de python de `cos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990562c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cos(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2b11969",
   "metadata": {},
   "source": [
    "Y lo comparamos con el tiempo de ejecución promedio para la función coseno de `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20462c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.cos(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_1(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "948931ed",
   "metadata": {},
   "source": [
    "> **Pregunta ❓:** ¿Se podrá medir el tiempo que toma cada instrucción por separado?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86f51719-cae9-4fe2-af68-9d016487b654",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compiladores\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/numba.png' width=600/>\n",
    "</center>\n",
    "\n",
    "Un proyecto interesante la librería **`Numba`** la cual está enfocada en **analizar y compilar funciones de Python**. Compiladores como Numba, diseñados para compilar código en ejecución (y no previo a la ejecución) se denomina compiladores **JIT** (just in time). \n",
    "\n",
    "Numba permite compilar funciones individuales de Python usado una *máquina virtual de bajo nivel* o LLVM por sus siglas en inglés (LLVM es un conjunto de herramientas pensadas para escribir compiladores).\n",
    "\n",
    "Por medio de LLVM Numba inspecciona funciones de Python y las compila utilizando una capa de representación intermedia similar a código *assembly*. La potencia de esta inspección radica en la inferencia de tipos de datos generando una versiones compiladas con tipos de datos estáticos.\n",
    "\n",
    "Numba se basa principalmente en el decorador `@jit` con el cual se definen las funciones a compilar.\n",
    "\n",
    "**Ejemplo: Calcular el valor de $\\pi$ usando Montecarlo**\n",
    "\n",
    "\n",
    "Idea: \n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/montecarlo.png' width=300 />\n",
    "<div/>\n",
    "    \n",
    "$$\\frac{\\text{area círculo}}{\\text{area cuadrado}} = \\frac{\\pi r^2}{(2r)^2} $$\n",
    "\n",
    "$$ 4* \\frac{\\text{area círculo}}{\\text{area cuadrado}} = \\pi $$\n",
    "\n",
    "\n",
    "Y después simulamos que lanzamos puntos al azar a nuestra figura y contamos: \n",
    "\n",
    "$$ 4* \\frac{\\text{puntos en el circulo}}{\\text{puntos en el cuadrado}} = \\pi $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd47f0b9-14a4-4d7b-b498-714961214c47",
   "metadata": {},
   "source": [
    "Para comprobar el aumento de rendimiento de la compilación, usaremos 3 implementaciones distintas:\n",
    "    \n",
    "    1. Python.\n",
    "    2. Numpy.\n",
    "    3. Python con Numba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b9fd9f4-0706-4f4b-a64f-e1998cebe034",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b285c-6aa7-4bc0-b478-39339a738eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def monte_carlo_pi_python(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe9fea-7931-48da-ba39-deabfc0091af",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_python(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ce85a-b0f1-4b9b-9006-98da13c5f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_python(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61c60368-8df5-4e94-9fb4-f1370fe6f483",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d77f8-6cb0-4496-8a20-3b9be6e7c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def monte_carlo_pi_numpy(nsamples):\n",
    "    acc = 0\n",
    "    x = np.random.rand(nsamples)\n",
    "    y = np.random.rand(nsamples)\n",
    "\n",
    "    op = x**2 + y**2\n",
    "    dentro_circulo = op[op < 1.0]\n",
    "\n",
    "    return 4.0 * np.count_nonzero(dentro_circulo) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d5065-7344-48ad-96a1-93911a58ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numpy(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c3388-39a0-4525-8e19-9c07f24fa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numpy(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "350d6a86-9667-4c3c-a802-1513ff3a78b0",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Numba`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e867c1b-b045-4322-b99a-515f5d358190",
   "metadata": {},
   "source": [
    "Y ahora probamos con una función compilada usando el decorador `@jit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc3f0-e002-47b3-a281-725979f3766d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def monte_carlo_pi_numba(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389ed98-bbdc-49e7-bcef-2313bc3894a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numba(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e63c0-5fec-4913-89bc-ee635da69637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numba(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16b881ed-b3ae-4eee-b030-eb6be21d68a0",
   "metadata": {},
   "source": [
    "### Numba y Numpy\n",
    "\n",
    "`Numba` también está diseñado para funcionar en conjunto con `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c574e-bbfc-49a0-8775-82fa1397d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def monte_carlo_pi_numpy_numba(nsamples):\n",
    "    acc = 0\n",
    "    x = np.random.rand(nsamples)\n",
    "    y = np.random.rand(nsamples)\n",
    "\n",
    "    op = x**2 + y**2\n",
    "    dentro_circulo = op[op < 1.0]\n",
    "\n",
    "    return 4.0 * np.count_nonzero(dentro_circulo) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631e193-991a-41ed-9364-7fb7e5c25508",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numpy_numba(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add4a97-84be-494b-8254-4993c2f34c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numpy_numba(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56e05fb5-eddc-4e0f-af5f-7ce6185cbbb2",
   "metadata": {},
   "source": [
    "### Importante: `Numba` solo compila código de Python y `Numpy`\n",
    "\n",
    "Está en general diseñado para optimizar tareas matemáticas y con ciclos.\n",
    "No entiende librerías más complejas como `pandas` por ejemplo.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bd564-9831-4242-a71a-50cfc98f2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = {\"a\": [1, 2, 3], \"b\": [20, 30, 40]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d8770-ac6e-4f98-a871-533e76c449da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pandas(a):  # Function will not benefit from Numba jit\n",
    "    df = pd.DataFrame.from_dict(a)  # Numba doesn't know about pd.DataFrame\n",
    "    df += 1  # Numba doesn't understand what this is\n",
    "    return df.cov()  # or this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a528c9b-47ac-422b-8974-379960147fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit use_pandas(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba041aa-cd92-48e7-82bc-57806747276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def use_pandas(a):  # Function will not benefit from Numba jit\n",
    "    df = pd.DataFrame.from_dict(a)  # Numba doesn't know about pd.DataFrame\n",
    "    df += 1  # Numba doesn't understand what this is\n",
    "    return df.cov()  # or this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da4c7a-c450-48cb-be5a-3be4f5f1c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pandas(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe99ff-d583-45b4-bf1e-95e073539746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit use_pandas(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72f2eaa0-1358-4ea0-a0c5-0d46e1001600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paralelismo\n",
    "\n",
    "El paralelismo se basa en el uso de múltiples unidades de computo de manera simulánea, con el el fin de mejorar la eficiencia en rutinas de código. La idea principal consite en enfrentar un problema de programación, dividiendolo en subunidades independientes y utilizar los núcleos disponibles de la máquina para resolver tales subunidades en paralelo.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/paralelo_vs_secuencial.jpeg'/>\n",
    "<center>\n",
    "Fuente: \n",
    "<a href='https://towardsdatascience.com/an-intro-to-parallel-computing-with-ray-d8503629485'>https://towardsdatascience.com/an-intro-to-parallel-computing-with-ray-d8503629485</a>\n",
    "    \n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a22a5d17-b567-4070-a97f-ebc0d1c1c42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Problemas Data Parallel\n",
    "\n",
    "Los problemas **Data Parallel** son aquellas en las que se le aplica una función particular sobre todos los datos (por ejemplo, multiplicar una matriz por un escalar).\n",
    "\n",
    "\n",
    "En este tipo de problema paralelizable, es importante que la función es exactamente la misma y que el calculo de esta es independiente de todas las otras funciones. Por lo mismo, estas tareas también son denominadas **perfectamente paralelizables**. \n",
    "\n",
    "Las operaciones elemento por elemento sobre arreglos poseen esta propiedad. \n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/cpu_gpu.jpg' width=500 />\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Fuente: \n",
    "<a href='https://www.nvidia.com/es-la/drivers/what-is-gpu-computing/'>Nvidia.</a>\n",
    "</div>\n",
    "\n",
    "  \n",
    "Imaginense la cantidad de operaciones simples que una GPU puede lograr hacer en paralelo. Por ejemplo, sumar una matriz con otra elemento a elemento.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df57ce35-39d9-4a4b-8148-b18dbfbe3743",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problemas Task Parallel\n",
    "\n",
    "Los problemas task parallel son aquellos que ejecutan varias tareas distintas en distintos hilos/procesos sobre distintos procesadores.\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/paralelismo_memoria.png' width=500 />\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "Fuente:    \n",
    "<a href='https://manningbooks.medium.com/explaining-mapreduce-with-ducks-f643c78e0b40'>https://manningbooks.medium.com/explaining-mapreduce-with-ducks-f643c78e0b40</a>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Por lo general, este tipo de tasks no son completamente independientes y necesitan compartir información. En estos casos, se debe tener en cuenta que la comunicación entre subunidades y los datos compartidos **quitan eficiencia** al problema que se resuelve, pues se incurre en *costos de comunicación*. \n",
    "\n",
    "La comunicación entre procesos es inherentemente costosa y puede llevar fallas de correctitud . Por lo general, se enfrenta el problema de costo de comunicación y correctud del manejo de memoria por medio de sistemas que se comunican por medio de **threads/hilos con memoria compartida** y **procesos con memoria distribuida**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "247f9d9e-059b-458d-87c7-bf61945b0922",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hilos de Procesamiento o Threads\n",
    "\n",
    "En el caso de memoria compartida, las subunidades involucradas en el programa tienen acceso a un espacio común de memoria, este por lo general es de acceso rápido. \n",
    "\n",
    "Si bien esto solventa el problema de velocidad de comunicación, el problema de correctitud sigue latente, por lo que se hace necesario utilizar técnicas de **sincronización**. \n",
    "\n",
    "La manera usual en la que se implementan procesos de memoria compartida es por medio de **threads o hilos de ejecución**. Estos consisten en subtareas originadas de un proceso en particular y que comparten recursos. \n",
    "\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/threads.jpg' width=500/>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "Fuente:\n",
    "<a href='https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/4_Threads.html'> https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/4_Threads.html </a>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f48539-fbec-4619-bd0f-f5efbee2d7ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Procesos\n",
    "\n",
    "Por otra parte, el concepto de memoria distribuida concibe cada subunidad como un proceso completamente separado del resto con su propio espacio de memoria asociado. En este caso, la comunicación entre procesos se debe manejar de manera explicita y es más costosa que en el caso de memoria compartida, sin embargo, se reduce el riesgo de generar errores en el manejo de memoria. \n",
    "\n",
    "Este tipo de paralelismos puede ser observadas en los distintos procesos que ejecuta nuestro computador.\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/thread_process.png' width=500/>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center>\n",
    "    Fuente:\n",
    "    <a href='https://www.javamex.com/tutorials/threads/how_threads_work.shtml'>https://www.javamex.com/tutorials/threads/how_threads_work.shtml</a>\n",
    "</center>\n",
    "\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> **Pregunta ❓**: ¿Qué aplicación de data science podría beneficiarse de la aplicación de procesos paralelos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66b40dea-6c0a-4f46-927b-cc95674bf31f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Threads y Procesos en Python\n",
    "\n",
    "Python puede manejar threads pero dado el diseño de su interprete, por defecto, se puede ejecutar solo una tarea a la vez, esto se conoce como **GIL** (Global Interpreter Lock). GIL provoca que cada vez que un hilo ejecute una orden de Python, se genere un bloqueo que solo será liberado una vez la ejecución del hilo termine.\n",
    "\n",
    "> **Esto hace que los hilos solo puedan ser ejecutados de manera secuencial.**\n",
    "\n",
    "Es decir, Python no puede ejecutar 2 o más hilos de ejecución al mismo tiempo usando más de un procesador.\n",
    "\n",
    "\n",
    "Aunque GIL evita la ejecución de hilos usando múltiples procesadores en paralelo, es posible utilizar procesos mediante algunas librerías. La principal es `multiprocessing`\n",
    "\n",
    "Multiprocessing ofrece una interfaz sencilla que incluye múltiples herramientas para manejar sincronozación y ejecución de tareas. Es posible importar esta librería de manera estándar. \n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "```\n",
    "\n",
    "Es posible crear procesos independientes por medio la clase `Process`, para ello basta extender el método `__init__` para inicializar los datos a procesar y generar el método `run` sobre el cual se ejecuta el proceso.\n",
    "\n",
    "**Ejemplo**\n",
    " \n",
    "Se genera un proceso independiente utilizando la clase `Process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd4ac3-2173-4bb0-b562-fac4cdfd9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "class Proceso_independiente(Process):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Mi número:\", self.num, \"\\nMe voy a dormir 10s 💤😴💤\")\n",
    "        time.sleep(10)\n",
    "        print(\"Desperté 😃\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd5b0221-969c-4492-9b07-7661039808f0",
   "metadata": {},
   "source": [
    "Para utilizar el proceso se instancia un objeto de la clase `Proceso_ind` y se llama el método `.start()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fade8-f0fd-467c-83f3-43c5c49ceff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(5)\n",
    "proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a74157",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(10)\n",
    "proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc1786-2251-4309-b320-4574b2aa1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"¿¿¿🤨??? Me puedo ejecutar sin esperar a que la celda anterior termine\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7677086-a786-4646-970a-a3b7ac42aed2",
   "metadata": {},
   "source": [
    "**Obs**:En el ejemplo anterior, no fue necesario utilizar el metodo anulado `.run()`, este es llamado por `.start()` de manera interna."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f6749c-98fe-4c5e-9a3b-97fba4930c0c",
   "metadata": {},
   "source": [
    "En el caso en que se requiera esperar la finalización de un conjunto de tareas paralelas para luego recopilar resultados, es posible utilizar el método `.join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348451f-608a-4413-93e8-b7ef07efcd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(5)\n",
    "proc.start()\n",
    "proc.join()\n",
    "\n",
    "print(\"Aquí tuve que esperar 😔\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f059a32b-0282-47d6-ae4c-17bb55e55797",
   "metadata": {},
   "source": [
    "Con la construcción actual, es posible levantar tantos procesos como se requiera, en esta caso se levantan 3 procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6291f45-dd9b-42d2-8914-9ef2f2910828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "class Proceso_independiente(Process):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Me voy a dormir 10s ({self.num})💤😴💤\\n\")\n",
    "        time.sleep(10)\n",
    "        print(f\"Desperté ({self.num})😃\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d4e5-608d-414c-8661-8d8fab839287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los 3 procesos\n",
    "procesos = (\n",
    "    Proceso_independiente(1),\n",
    "    Proceso_independiente(2),\n",
    "    Proceso_independiente(3),\n",
    ")\n",
    "\n",
    "# Se mide el tiempo de ejecucion\n",
    "start = time.time()\n",
    "\n",
    "# Iniciar todos los procesos\n",
    "for p in procesos:\n",
    "    p.start()\n",
    "\n",
    "# Esperar a que terminen todos los procesos\n",
    "for p in procesos:\n",
    "    p.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(\"Tiempo de ejecución: \", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1dde08-944a-4e67-a7f6-babd722394eb",
   "metadata": {},
   "source": [
    "Estos tres procesos corren de manera paralela, pues su tiempo de ejecución total es aproximado al tiempo de ejecución individual. \n",
    "\n",
    "Es necesario comprender que el orden de ejecución de procesos paralelos no es necesariamente ordenando y predecible pues depende de cómo el sistema operativo asigne los recursos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cca43fc-fc3d-4892-b2e1-69334c45e3e3",
   "metadata": {},
   "source": [
    "### Memoria Compartida y Dataraces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5609dfb8-e765-4b07-99be-dea9d5810189",
   "metadata": {},
   "source": [
    "Un data race es una situación que ocurre cuando uno o más hilos acceden concurrentemente a una posición de memoria o variable, al menos uno está escribiendo y al menos uno no está sincronizado con los otros hilos.\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/datarace_1.png' width=400/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Ejecución secuencial en memoria compartida por threads.\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Race_condition'>Wikipedia</a>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/datarace_2.png' width=400/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Ejecución paralela en memoria compartida por threads.\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Race_condition'>Wikipedia</a>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "**La solución es tener mecanismos de sincronización** de hilos. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f980ca12",
   "metadata": {},
   "source": [
    "\n",
    "### Ejemplo en `multiprocessing`\n",
    "\n",
    "\n",
    "El comportamiento predeterminado de `multiprocessing` es generar procesos con memoria independiente, sin embargo, permite definir ciertas variables en memoria compartida. Para definir una variable en memoria compartida se utiliza la clase `Value`, a esta clase se le entrega un tipo de dato que puede ser `i` para entero, `f` para flotante, `d` para doble precisión entre otros. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b3fc9-1a31-40ff-bb87-cfc9e50efbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value\n",
    "\n",
    "comp_var = Value(\"d\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fe738b8-f485-4f52-a5ac-c14f81b020a6",
   "metadata": {},
   "source": [
    "Al utilizar variables en memoria compartida se deben tener en cuenta los procesos que acceden a ella, manejando la *concurrencia*, es decir, si los procesos pueden acceder a dichas variables de manera simultanea u ordenada. Por lo general en la actualización de valores unidimensionales se debe tener en cuenta la concurrencia bloqueando el acceso simultaneo. En arreglos se puede permitir tal manipulación siempre que los computos sean independientes. \n",
    "\n",
    "Para bloquear el acceso a una variable compartida se hace uso de la clase `Lock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbefb31-c9e2-46ea-a054-6bac2611b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Lock\n",
    "\n",
    "lock = Lock()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a221d22-717b-405f-8b9d-7ff586f5b8d0",
   "metadata": {},
   "source": [
    "A continuación se genera una rutina que accede a una variable de memoria compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2453437-182a-4b31-87e2-5c645e3ce596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value\n",
    "\n",
    "\n",
    "class Process_shared(Process):\n",
    "    def __init__(self, var, n=10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            self.var.value += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2ba6b92-367f-434b-afe9-2e176e7d97fe",
   "metadata": {},
   "source": [
    "El proceso asociado toma un valor y le añade 1 hasta `n = 10000` veces por proceso. Se crea el valor inicial y se inicializan 3 procesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8056121-d6c1-4dd2-b007-2cdc2fb4e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value(\"i\")\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared(var) for i in range(3)]\n",
    "\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "\n",
    "    print(var.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc65807e-50a7-4929-abe3-e55643f61964",
   "metadata": {},
   "source": [
    "Se prueba el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f723ea8-06a4-49c2-a379-bbe4bd1b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6bc4ec-fd1a-45d4-9792-b60be221382c",
   "metadata": {},
   "source": [
    "Como se puede ver, el resultado no es necesariamente 30.000, esto se debe al acceso simultaneo y aleatorio de los procesos a `var`, para solucionar este problema se hace uso de `lock`, para ello se redefine la clase `Process_shared` observando que lock es un *context manager*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cb69d-18c7-41da-a0bd-d51f2b06a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process_shared_lock(Process):\n",
    "    def __init__(self, var, n=10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            with lock:\n",
    "                self.var.value += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "863e887a-0d1a-469d-86cd-11ed086ceba2",
   "metadata": {},
   "source": [
    "Se redefine la prueba asociada y se ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964469f-ee69-45b2-a6d1-def3de8097b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value(\"i\")\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared_lock(var) for i in range(3)]\n",
    "\n",
    "    [p.start() for p in procs]\n",
    "    [p.join() for p in procs]\n",
    "\n",
    "    print(var.value)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b281fb5-b9e4-45d8-a955-32e186044360",
   "metadata": {},
   "source": [
    "Con lo cual se obtiene el resultado buscado.\n",
    "\n",
    "Sin embargo, coordinar procesos más complejos se torna tedioso y complejo, además de ser susceptible a errores.\n",
    "Por lo general, se recomienda, a menos que sea estrictamente necesario, a librerías que facilitan la paralelización, como las que vamos a ver a continuación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4fd2cfa-56e9-4c08-94de-5138b94c4903",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Paralelización con `Joblib`\n",
    "\n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/joblib.png' width=200>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71e8875-84aa-4168-be0a-1620404aeb79",
   "metadata": {},
   "source": [
    "Otra forma de paralelizar de forma relativamente sencilla es usar la librería `joblib`. \n",
    "Esta permite ejecutar funciones de forma paralela, pero ahora de manera funcional. \n",
    "Es decir, le entregamos una función y una lista de argumentos y ejecuta una función con dichos argumentos de forma paralela.\n",
    "\n",
    "Para esto, utiliza el decorador `delayed` sobre una función (lo que la transforma a lazy, es decir, no se ejecuta instantaneamente). Luego a través del objeto `Parallel` que toma el número de trabajos concurrentes que se ejecutarán (`n_jobs`) ejecuta las funciones con sus parámetros.\n",
    "\n",
    "El siguiente ejemplo veremos como paralelizar el cálculo de coseno sobre una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "[np.cos(i) for i in np.arange(0, 1, 0.1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e750fb3d-fa80-4513-8e14-b8d4b36fdd07",
   "metadata": {},
   "source": [
    "La notación es muy similar a un list comprehension, solo que con 2 diferencias:\n",
    "\n",
    "- Se reemplazan los corchetes exteriores `[f(i) for i in ...]` por paréntesis `(f(i) for i in ...)` (Esto da lugar a un generador en vez de una lista).\n",
    "- Se encapsula la función a aplicar a cada elemento con la función `delayed`, o sea, `f(i)` por `delayed(f)(i)`.\n",
    "\n",
    "Luego, lo anterior se le pasa como argumento a un Parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cbecb-4af7-49a3-b2a4-45a135ffdc53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# n_jobs=-1 indica que se usarán todos los procesadores disponibles.\n",
    "Parallel(n_jobs=-1)(delayed(np.cos)(i) for i in np.arange(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38219e2-b33b-4617-bf45-b1262227b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [np.cos(i) for i in np.arange(0, 1, 0.001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208c066-037e-4fd9-900b-3108705ed30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Parallel(n_jobs=-1)(delayed(np.cos)(i) for i in np.arange(0, 1, 0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81d8db37-d68c-48f9-8506-230171f86419",
   "metadata": {},
   "source": [
    "Para tareas numéricas no es tan efectivo (ya existe un cierto overhead/coste de generar los subprocesos), pero para tareas pesadas, se comporta bastante bien.\n",
    "\n",
    "Para este ejemplo, leeremos 50 veces archivo con números aleatorios en forma secuencial y en forma paralelizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f773-c677-4d91-b93b-b2fb53e56265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def leer_archivo(_):\n",
    "    _ = pd.read_csv(\"https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo//num_aleatorios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d798fa4-8f7b-4619-9cc7-cc07f83c8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [leer_archivo(_) for _ in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81e619-afc1-4d05-9496-496dc0bc96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Parallel(n_jobs=-1)(delayed(leer_archivo)(_) for _ in range(0, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a56343c1-9281-463c-aa34-85ae685c7d78",
   "metadata": {},
   "source": [
    "Ahora si notamos diferencias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "504f4ce9",
   "metadata": {},
   "source": [
    "### Asincronía y Corrutinas\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/corrutinas.png' />\n",
    "</center>\n",
    "\n",
    "En general, se utiliza más en el desarrollo web/software para no bloquear la ejecución de código al solicitar datos a un servidor externo o ejecutar un proceso muy pesado.\n",
    "\n",
    "\n",
    "> **Pregunta ❓**: ¿Qué aplicación de data science podría beneficiarse de la asincronía?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d4bd170-c9bb-4d5e-b583-7ed801352710",
   "metadata": {},
   "source": [
    "## Procesamiento Distribuido\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/distributed.png'/>\n",
    "\n",
    "El procesamiento distribuido hace referencia a la ejecución de tareas utilizando múltiples máquinas. Por lo general se refiere al trabajo con clusters de procesamiento y suele llevarse a cabo por medio de herramientas como [`Spark`](https://spark.apache.org/) o [`Dask`](https://www.dask.org/).\n",
    "\n",
    "Diferencias entre spark y dask: https://docs.dask.org/en/stable/spark.html\n",
    "\n",
    "En esta última sección estudiaremos `Dask` para procesar `DataFrames`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "953daa93-b98e-4c50-b982-f6304fc349d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### `Dask`\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask.jpg' width=300>\n",
    "</div>\n",
    "\n",
    "Dask permite escalar procesos de Python (ya sea en un computador personal o un cluster) de manera sencilla. Provee de funcionalidades para tratar, por medio de procesamiento multi-core, con datsets masivos **que por lo general no caben en memoria.**\n",
    "\n",
    "`Dask` fue implementado como un reemplazo de `Numpy` y `Pandas`, por ende su interfaz de usuario (API) es muy similar.\n",
    "Los `DataFrames` de Dask son en términos prácticos conjuntos de `DataFrames` de pandas. Dicha separación permite ejecutar operaciones distribuidas y paralelas de forma muy eficiente.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc063679-0fd9-4dfb-8d8f-3bff133be931",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask.png' width=600 />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b93ab7d-4229-4bed-b651-3ddef71fa735",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask_mimic.png' width=700>\n",
    "</center>\n",
    "\n",
    "Pueden encontrar mayor información en la página oficial del proyecto:\n",
    "\n",
    "https://docs.dask.org/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3df70b-d038-4f3f-ad45-74d020c0912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"dask[dataframe]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3eb2393f-07ee-46fc-adfb-83649a5998bf",
   "metadata": {},
   "source": [
    "#### Pandas vs Dask\n",
    "\n",
    "##### Datos aleatorios con `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989eb50-a3c6-4aa4-9bb4-c1da1507b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generamos datos aleatorios (disminuir en caso de no contar con suficiente memoria)\n",
    "df = pd.DataFrame(np.random.random((2000000,200)))\n",
    "\n",
    "# generamos categorías a partir de bins para luego agregar\n",
    "df[0] = pd.cut(df[0], 20)\n",
    "df[1] = pd.cut(df[1], 20)\n",
    "df[2] = pd.cut(df[2], 20)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6143e812-d647-468e-a00d-f5cea0765f57",
   "metadata": {},
   "source": [
    "La prueba será cuanto se demora en ejecutar un `groupby(..).mean()` sobre las categorías generadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9864d-520e-42ef-b1e3-53b28835cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04a5f91f-6b28-41d0-943f-c6603889662d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Inicializar `dask.dataframe`\n",
    "\n",
    "Ahora, generamos un `Dask DataFrame` desde pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94000af2-a0a1-480d-908e-5b2cfed041a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "ddf = dd.from_pandas(df, npartitions=5)\n",
    "ddf.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b443731-d353-49ba-8906-f4314577865e",
   "metadata": {},
   "source": [
    "Vemamos que pasa si hacemos la misma operación que antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924b7ea-1e82-4ffc-9777-3eb00a525112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fba052b2-d9b1-4f7d-8087-986e736dd9e9",
   "metadata": {},
   "source": [
    "No produjo ningún resultados. Esto es porque Dask es **Lazy**, es decir, se ejecuta solo cuando alguien demanda su ejecución.\n",
    "Esto se puede lograr a partir del método `compute()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cb0c3-8fde-4f5e-a3b7-af10579cfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58719505-814a-41a9-94ab-be72d916b725",
   "metadata": {},
   "source": [
    "Incluso se puede visualizar como se computa la operación distribuida a través de el siguiente método:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13ac23-d602-4a70-8ee1-8e5f9c717d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean().visualize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2280461-9e3c-424d-b00b-d2f5b983928d",
   "metadata": {},
   "source": [
    "##### Comparación de tiempos\n",
    "\n",
    "En las siguientes celdas ejecutamos al comparación de tiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70538bc-d5e6-4068-833b-4bbe21de2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab1e67-9cd0-4780-95b8-ab13d76f6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ddf.groupby([0, 1, 2]).mean().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da8369a5-5997-44c9-ba8f-0f75d7345d78",
   "metadata": {},
   "source": [
    "Podemos ver que **Dask** no es más rápido que **pandas** para la cantidad de datos anterior `(500000 x 200) ~ 752.9 MB`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e09b08da-7a4c-4392-b922-cc512377e874",
   "metadata": {},
   "source": [
    "Nuevamente, esto se debe al overhead / gasto adicional que implica lanzar varios procesos para ejecutar tareas en paralelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468488b0",
   "metadata": {},
   "source": [
    "## Polars\n",
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg\" width=450>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "Blazingly Fast DataFrame Library \n",
    "</div>\n",
    "\n",
    "Nueva librería alternativa a pandas enfocada en alto rendimiento y programado íntegramente en [Rust](https://www.rust-lang.org/es).\n",
    "\n",
    "Sus principios son:\n",
    "\n",
    "- **Rápido**: Polars está escrito desde cero, diseñado cerca de la máquina y sin dependencias externas.\n",
    "- **E/S**: Soporte para todas las capas comunes de almacenamiento de datos: local, almacenamiento en la nube y bases de datos.\n",
    "- **Fácil de usar**: Escriba sus consultas de la forma en que fueron concebidas. Polars, internamente, determinará la forma más eficiente de ejecutar utilizando su optimizador de consultas.\n",
    "- **_Out of core_**: Polars soporta la transformación de datos fuera del núcleo con su API de streaming. Permitiéndole procesar sus resultados sin requerir que todos sus datos estén en memoria al mismo tiempo.\n",
    "- **Paralelo**: Polars utiliza plenamente la potencia de su máquina dividiendo la carga de trabajo entre los núcleos de CPU disponibles sin ninguna configuración adicional.\n",
    "- **Motor de consulta vectorizado**: Polars utiliza Apache Arrow, un formato de datos en columnas, para procesar sus consultas de forma vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acada1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3dd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl_df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85dfb1d9-164a-466a-ac04-c67e84618a40",
   "metadata": {},
   "source": [
    "### Debo usar estos frameworks?\n",
    "\n",
    "Si tu dataset cabe en memoria comodamente y no es muy grande, entonces no es necesario usar `Dask`. Simplemente agregará una capa de complejidad al desarrollo.\n",
    "\n",
    "Por otra parte, si el dataset con el cuál están trabajando es masivo, entonces dichas librerías son un buen factor a considerar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb25b97",
   "metadata": {},
   "source": [
    "## Y para usar la GPU?\n",
    "\n",
    "Pueden utilizar estas alternativas:\n",
    "\n",
    "- [Cupy](https://docs.cupy.dev/en/stable/user_guide/basic.html) - Implementación de `NumPy/SciPy` usando `CUDA` (para GPUs nvidia)\n",
    "- [Rapids](https://rapids.ai/start.html): Colección de librerías basadas en `CUDA` que al igual que la alternativa anterior, mejora el rendimiento a través de la GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
