{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958072d5-97d3-4e0a-bb65-a52954f1401e",
   "metadata": {},
   "source": [
    "# Clase 23: Compilaci√≥n, Paralelismo y Computaci√≥n Distribuida\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "**Profesor: Pablo Badilla**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7701ae9-abcd-4fee-94fd-100202a99ab7",
   "metadata": {},
   "source": [
    "## Objetivos de la clase:\n",
    "\n",
    "- Aprender a optimizar c√≥digo a trav√©s de `JIT`.\n",
    "- Comprender el paralelismo de tareas.\n",
    "- Aprender a paralelizar tareas por medio de funciones en `Joblib`\n",
    "- Comprender la idea general de computaci√≥n distribuida.\n",
    "- Analizar las opciones para computaci√≥n distribuida: `Dask`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d64bdcdb",
   "metadata": {},
   "source": [
    "## Motivaci√≥n\n",
    "\n",
    "El flujo de trabajo en ciencia de datos consta de **numerosas rutinas de carga, procesamiento y visualizaci√≥n**. Lo ideal es que dise√±emos estas rutinas de la forma m√°s optima posible con el fin de reducir recursos, tiempos de carga utilizados y sus costos asociados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979e870b",
   "metadata": {},
   "source": [
    "\n",
    "## Lenguajes de Programaci√≥n\n",
    "\n",
    "El lenguaje de m√°quina es el conjunto de instrucciones que el hardware es capaz de interpretar y procesar.\n",
    "A trav√©s de estas instrucciones podemos lograr que nuestro procesador ejecute distintos tipos de acciones muy b√°sicas. \n",
    "Este conjuntos de lenguajes es comunmente conocido como *lenguaje de bajo nivel*\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/codigo_maquina.png' width=400 />\n",
    "<center/>\n",
    "\n",
    "<center>Por suerte no tenemos que si quiera pensar en esto...</center>\n",
    "    \n",
    "<center> \n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Machine_code#/media/File:W65C816S_Machine_Code_Monitor.jpeg'>Wikipedia </a>\n",
    "</center>\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7e10b3-aeb6-4dd7-bd5d-d1a30d1eb926",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lenguajes Compilados vs Intepretados\n",
    "\n",
    "Existen dos enfoques principales para convertir un c√≥digo de lenguaje de alto nivel a uno de bajo nivel: que el lenguaje sea **Compilado** o **Interpretado**.\n",
    "\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/tipos_lenguajes.png' width=800 />\n",
    "</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4a2f75a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computaci√≥n de alto Rendimiento con Python\n",
    "\n",
    "Python es utilizado transversalmente, ya sea en la industria o en la academia. Dentro de sus cualidades se encuentra la portabilidad de c√≥digo, sintaxis intuitiva, disponibilidad de herramientas y documentaci√≥n. Sin embargo, al ser un lenguaje interpretado se pierden ciertas caracter√≠sticas intr√≠nsicas de los lenguajes de bajo nivel como C, C++ y Fortran.\n",
    "\n",
    "En esta y la pr√≥xima clase estudiaremos distintas herramientas para mejorar el rendimiento del interprete, como el uso eficiente de objetos base y la aplicaci√≥n de t√©cnicas de paralelismo y compilaci√≥n utilizando tanto librer√≠as nativas, como desarrolladas por terceros. \n",
    "\n",
    "\n",
    "> **Pregunta ‚ùì:** ¬øSer√° conveniente programar siempre pensando crear c√≥digo √≥ptimo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c29f46b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimizaci√≥n del C√≥digo\n",
    "\n",
    " Como directriz general, se recomienda llevar el proceso de desarrollo en dos etapas:\n",
    " \n",
    "1. La primera consiste en **generar c√≥digo correcto, comprensibles y mantenibles**, evitando la sobre-optimizaci√≥n prematura de c√≥digo. \n",
    "\n",
    "2. Como segunda etapa, se recomienda comenzar con los procesos de **optimizaci√≥n de c√≥digo**. Esto pues, las herramientas que permiten mejorar los aspectos computacionales, interfieren en la sencillez del c√≥digo, entorpeciendo los procesos de depuraci√≥n y mantenci√≥n. \n",
    "\n",
    "Una vez que las rutinas est√°n implementadas de manera correcta, la mejor manera de enfocar los esfuerzos, pasa por **perfilar** (*profiling*) el c√≥digo. Esto consiste en encontrar las zonas de c√≥digo criticas en cuanto a carga computacional. La manera m√°s directa de encontrar estas zonas, es por medio del uso de contadores de tiempo o *timers*.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d674ef72",
   "metadata": {},
   "source": [
    "### Medici√≥n del Tiempo de Ejecuci√≥n ‚è∞\n",
    "\n",
    "\n",
    "El tiempo de ejecuci√≥n es el tiempo tomado por algun segemento de c√≥digo, funci√≥n en completar su ejecuci√≥n.\n",
    "\n",
    "En Python, la forma m√°s sencilla de medir el tiempo de ejecuci√≥n es a trav√©s de la librer√≠a `time`. El ejemplo siguiente muestra como utilizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import cos, sin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b13ba90a",
   "metadata": {},
   "source": [
    "Definimos un rango de datos a operar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b295a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.1 * i for i in range(100000)]\n",
    "\n",
    "x[0:10]  # veamos los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ee1d307",
   "metadata": {},
   "source": [
    "Luego definimos la funci√≥n que mediremos. Esta simplemente calcula $(\\sin(val) + \\cos(val)^2)^{1/3}$ y luego retorna su valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(val):\n",
    "    return (sin(val) + cos(val) ** 2) ** (1 / 9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbd24073",
   "metadata": {},
   "source": [
    "Ahora, estudiamos el tiempo de ejecuci√≥n por medio de la funci√≥n `process_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiempo inicial\n",
    "t0 = time.process_time()\n",
    "\n",
    "for i in x:\n",
    "    func_1(i)\n",
    "\n",
    "# tiempo final\n",
    "t1 = time.process_time()\n",
    "\n",
    "# el tiempo transcurrido es simplemente el delta entre t1 y t0\n",
    "print(\"Tiempo transcurrido\", t1 - t0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "654e69a7",
   "metadata": {},
   "source": [
    "> **Pregunta ‚ùì:** ¬øSi ejecutamos nuevamente la celda anterior, obtendremos los mismos tiempos? ¬øExistir√° alguna forma m√°s consistente de medir el tiempo de ejecuci√≥n del c√≥digo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5189c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### `timeit`\n",
    "\n",
    "En algunas ocasiones se desea medir el tiempo de ejecuci√≥n para tareas sencillas, la librer√≠a est√°ndar de Python provee el m√≥dulo `timeit`. En la pr√°ctica, una llamada de `timeit` ejecuta por defecto 10.000.000 el c√≥digo (variable seg√∫n cu√°nto se demore el proceso) y repite 7 veces el experimento. Lluego reporta el tiempo de ejecuci√≥n promedio.\n",
    "\n",
    "Este puede ser utilizado directamente en la consola interactiva IPython o en notebooks de Jupyter por medio del comando m√°gico `%timeit` para el caso de una linea de c√≥digo y `%%timeit` para medir toda la celda. \n",
    "\n",
    "Documentaci√≥n de `%timeit`: [Timeit Magic en la documentaci√≥n de Ipython](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19a2f9c2",
   "metadata": {},
   "source": [
    "\n",
    "**Ejemplo**\n",
    "\n",
    "\n",
    "Medimos la eficiencia de la implementaci√≥n original de python de `cos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990562c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cos(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2b11969",
   "metadata": {},
   "source": [
    "Y lo comparamos con el tiempo de ejecuci√≥n promedio para la funci√≥n coseno de `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20462c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.cos(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_1(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "948931ed",
   "metadata": {},
   "source": [
    "> **Pregunta ‚ùì:** ¬øSe podr√° medir el tiempo que toma cada instrucci√≥n por separado?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86f51719-cae9-4fe2-af68-9d016487b654",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compiladores\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/numba.png' width=600/>\n",
    "</center>\n",
    "\n",
    "Un proyecto interesante la librer√≠a **`Numba`** la cual est√° enfocada en **analizar y compilar funciones de Python**. Compiladores como Numba, dise√±ados para compilar c√≥digo en ejecuci√≥n (y no previo a la ejecuci√≥n) se denomina compiladores **JIT** (just in time). \n",
    "\n",
    "Numba permite compilar funciones individuales de Python usado una *m√°quina virtual de bajo nivel* o LLVM por sus siglas en ingl√©s (LLVM es un conjunto de herramientas pensadas para escribir compiladores).\n",
    "\n",
    "Por medio de LLVM Numba inspecciona funciones de Python y las compila utilizando una capa de representaci√≥n intermedia similar a c√≥digo *assembly*. La potencia de esta inspecci√≥n radica en la inferencia de tipos de datos generando una versiones compiladas con tipos de datos est√°ticos.\n",
    "\n",
    "Numba se basa principalmente en el decorador `@jit` con el cual se definen las funciones a compilar.\n",
    "\n",
    "**Ejemplo: Calcular el valor de $\\pi$ usando Montecarlo**\n",
    "\n",
    "\n",
    "Idea: \n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/montecarlo.png' width=300 />\n",
    "<div/>\n",
    "    \n",
    "$$\\frac{\\text{area c√≠rculo}}{\\text{area cuadrado}} = \\frac{\\pi r^2}{(2r)^2} $$\n",
    "\n",
    "$$ 4* \\frac{\\text{area c√≠rculo}}{\\text{area cuadrado}} = \\pi $$\n",
    "\n",
    "\n",
    "Y despu√©s simulamos que lanzamos puntos al azar a nuestra figura y contamos: \n",
    "\n",
    "$$ 4* \\frac{\\text{puntos en el circulo}}{\\text{puntos en el cuadrado}} = \\pi $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd47f0b9-14a4-4d7b-b498-714961214c47",
   "metadata": {},
   "source": [
    "Para comprobar el aumento de rendimiento de la compilaci√≥n, usaremos 3 implementaciones distintas:\n",
    "    \n",
    "    1. Python.\n",
    "    2. Numpy.\n",
    "    3. Python con Numba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b9fd9f4-0706-4f4b-a64f-e1998cebe034",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b285c-6aa7-4bc0-b478-39339a738eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def monte_carlo_pi_python(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe9fea-7931-48da-ba39-deabfc0091af",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_python(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ce85a-b0f1-4b9b-9006-98da13c5f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_python(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61c60368-8df5-4e94-9fb4-f1370fe6f483",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d77f8-6cb0-4496-8a20-3b9be6e7c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def monte_carlo_pi_numpy(nsamples):\n",
    "    acc = 0\n",
    "    x = np.random.rand(nsamples)\n",
    "    y = np.random.rand(nsamples)\n",
    "\n",
    "    op = x**2 + y**2\n",
    "    dentro_circulo = op[op < 1.0]\n",
    "\n",
    "    return 4.0 * np.count_nonzero(dentro_circulo) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d5065-7344-48ad-96a1-93911a58ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numpy(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c3388-39a0-4525-8e19-9c07f24fa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numpy(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "350d6a86-9667-4c3c-a802-1513ff3a78b0",
   "metadata": {},
   "source": [
    "### $\\pi$ con Montecarlo en `Numba`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e867c1b-b045-4322-b99a-515f5d358190",
   "metadata": {},
   "source": [
    "Y ahora probamos con una funci√≥n compilada usando el decorador `@jit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccc3f0-e002-47b3-a281-725979f3766d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def monte_carlo_pi_numba(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389ed98-bbdc-49e7-bcef-2313bc3894a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numba(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e63c0-5fec-4913-89bc-ee635da69637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numba(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16b881ed-b3ae-4eee-b030-eb6be21d68a0",
   "metadata": {},
   "source": [
    "### Numba y Numpy\n",
    "\n",
    "`Numba` tambi√©n est√° dise√±ado para funcionar en conjunto con `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c574e-bbfc-49a0-8775-82fa1397d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def monte_carlo_pi_numpy_numba(nsamples):\n",
    "    acc = 0\n",
    "    x = np.random.rand(nsamples)\n",
    "    y = np.random.rand(nsamples)\n",
    "\n",
    "    op = x**2 + y**2\n",
    "    dentro_circulo = op[op < 1.0]\n",
    "\n",
    "    return 4.0 * np.count_nonzero(dentro_circulo) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631e193-991a-41ed-9364-7fb7e5c25508",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_numpy_numba(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add4a97-84be-494b-8254-4993c2f34c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi_numpy_numba(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56e05fb5-eddc-4e0f-af5f-7ce6185cbbb2",
   "metadata": {},
   "source": [
    "### Importante: `Numba` solo compila c√≥digo de Python y `Numpy`\n",
    "\n",
    "Est√° en general dise√±ado para optimizar tareas matem√°ticas y con ciclos.\n",
    "No entiende librer√≠as m√°s complejas como `pandas` por ejemplo.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bd564-9831-4242-a71a-50cfc98f2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = {\"a\": [1, 2, 3], \"b\": [20, 30, 40]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d8770-ac6e-4f98-a871-533e76c449da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pandas(a):  # Function will not benefit from Numba jit\n",
    "    df = pd.DataFrame.from_dict(a)  # Numba doesn't know about pd.DataFrame\n",
    "    df += 1  # Numba doesn't understand what this is\n",
    "    return df.cov()  # or this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a528c9b-47ac-422b-8974-379960147fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit use_pandas(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba041aa-cd92-48e7-82bc-57806747276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def use_pandas(a):  # Function will not benefit from Numba jit\n",
    "    df = pd.DataFrame.from_dict(a)  # Numba doesn't know about pd.DataFrame\n",
    "    df += 1  # Numba doesn't understand what this is\n",
    "    return df.cov()  # or this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da4c7a-c450-48cb-be5a-3be4f5f1c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pandas(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe99ff-d583-45b4-bf1e-95e073539746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit use_pandas(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72f2eaa0-1358-4ea0-a0c5-0d46e1001600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paralelismo\n",
    "\n",
    "El paralelismo se basa en el uso de m√∫ltiples unidades de computo de manera simul√°nea, con el el fin de mejorar la eficiencia en rutinas de c√≥digo. La idea principal consite en enfrentar un problema de programaci√≥n, dividiendolo en subunidades independientes y utilizar los n√∫cleos disponibles de la m√°quina para resolver tales subunidades en paralelo.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/paralelo_vs_secuencial.jpeg'/>\n",
    "<center>\n",
    "Fuente: \n",
    "<a href='https://towardsdatascience.com/an-intro-to-parallel-computing-with-ray-d8503629485'>https://towardsdatascience.com/an-intro-to-parallel-computing-with-ray-d8503629485</a>\n",
    "    \n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a22a5d17-b567-4070-a97f-ebc0d1c1c42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Problemas Data Parallel\n",
    "\n",
    "Los problemas **Data Parallel** son aquellas en las que se le aplica una funci√≥n particular sobre todos los datos (por ejemplo, multiplicar una matriz por un escalar).\n",
    "\n",
    "\n",
    "En este tipo de problema paralelizable, es importante que la funci√≥n es exactamente la misma y que el calculo de esta es independiente de todas las otras funciones. Por lo mismo, estas tareas tambi√©n son denominadas **perfectamente paralelizables**. \n",
    "\n",
    "Las operaciones elemento por elemento sobre arreglos poseen esta propiedad. \n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/cpu_gpu.jpg' width=500 />\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Fuente: \n",
    "<a href='https://www.nvidia.com/es-la/drivers/what-is-gpu-computing/'>Nvidia.</a>\n",
    "</div>\n",
    "\n",
    "  \n",
    "Imaginense la cantidad de operaciones simples que una GPU puede lograr hacer en paralelo. Por ejemplo, sumar una matriz con otra elemento a elemento.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df57ce35-39d9-4a4b-8148-b18dbfbe3743",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problemas Task Parallel\n",
    "\n",
    "Los problemas task parallel son aquellos que ejecutan varias tareas distintas en distintos hilos/procesos sobre distintos procesadores.\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/paralelismo_memoria.png' width=500 />\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "Fuente:    \n",
    "<a href='https://manningbooks.medium.com/explaining-mapreduce-with-ducks-f643c78e0b40'>https://manningbooks.medium.com/explaining-mapreduce-with-ducks-f643c78e0b40</a>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Por lo general, este tipo de tasks no son completamente independientes y necesitan compartir informaci√≥n. En estos casos, se debe tener en cuenta que la comunicaci√≥n entre subunidades y los datos compartidos **quitan eficiencia** al problema que se resuelve, pues se incurre en *costos de comunicaci√≥n*. \n",
    "\n",
    "La comunicaci√≥n entre procesos es inherentemente costosa y puede llevar fallas de correctitud . Por lo general, se enfrenta el problema de costo de comunicaci√≥n y correctud del manejo de memoria por medio de sistemas que se comunican por medio de **threads/hilos con memoria compartida** y **procesos con memoria distribuida**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "247f9d9e-059b-458d-87c7-bf61945b0922",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hilos de Procesamiento o Threads\n",
    "\n",
    "En el caso de memoria compartida, las subunidades involucradas en el programa tienen acceso a un espacio com√∫n de memoria, este por lo general es de acceso r√°pido. \n",
    "\n",
    "Si bien esto solventa el problema de velocidad de comunicaci√≥n, el problema de correctitud sigue latente, por lo que se hace necesario utilizar t√©cnicas de **sincronizaci√≥n**. \n",
    "\n",
    "La manera usual en la que se implementan procesos de memoria compartida es por medio de **threads o hilos de ejecuci√≥n**. Estos consisten en subtareas originadas de un proceso en particular y que comparten recursos. \n",
    "\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/threads.jpg' width=500/>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "Fuente:\n",
    "<a href='https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/4_Threads.html'> https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/4_Threads.html </a>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f48539-fbec-4619-bd0f-f5efbee2d7ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Procesos\n",
    "\n",
    "Por otra parte, el concepto de memoria distribuida concibe cada subunidad como un proceso completamente separado del resto con su propio espacio de memoria asociado. En este caso, la comunicaci√≥n entre procesos se debe manejar de manera explicita y es m√°s costosa que en el caso de memoria compartida, sin embargo, se reduce el riesgo de generar errores en el manejo de memoria. \n",
    "\n",
    "Este tipo de paralelismos puede ser observadas en los distintos procesos que ejecuta nuestro computador.\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/thread_process.png' width=500/>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center>\n",
    "    Fuente:\n",
    "    <a href='https://www.javamex.com/tutorials/threads/how_threads_work.shtml'>https://www.javamex.com/tutorials/threads/how_threads_work.shtml</a>\n",
    "</center>\n",
    "\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> **Pregunta ‚ùì**: ¬øQu√© aplicaci√≥n de data science podr√≠a beneficiarse de la aplicaci√≥n de procesos paralelos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66b40dea-6c0a-4f46-927b-cc95674bf31f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Threads y Procesos en Python\n",
    "\n",
    "Python puede manejar threads pero dado el dise√±o de su interprete, por defecto, se puede ejecutar solo una tarea a la vez, esto se conoce como **GIL** (Global Interpreter Lock). GIL provoca que cada vez que un hilo ejecute una orden de Python, se genere un bloqueo que solo ser√° liberado una vez la ejecuci√≥n del hilo termine.\n",
    "\n",
    "> **Esto hace que los hilos solo puedan ser ejecutados de manera secuencial.**\n",
    "\n",
    "Es decir, Python no puede ejecutar 2 o m√°s hilos de ejecuci√≥n al mismo tiempo usando m√°s de un procesador.\n",
    "\n",
    "\n",
    "Aunque GIL evita la ejecuci√≥n de hilos usando m√∫ltiples procesadores en paralelo, es posible utilizar procesos mediante algunas librer√≠as. La principal es `multiprocessing`\n",
    "\n",
    "Multiprocessing ofrece una interfaz sencilla que incluye m√∫ltiples herramientas para manejar sincronozaci√≥n y ejecuci√≥n de tareas. Es posible importar esta librer√≠a de manera est√°ndar. \n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "```\n",
    "\n",
    "Es posible crear procesos independientes por medio la clase `Process`, para ello basta extender el m√©todo `__init__` para inicializar los datos a procesar y generar el m√©todo `run` sobre el cual se ejecuta el proceso.\n",
    "\n",
    "**Ejemplo**\n",
    " \n",
    "Se genera un proceso independiente utilizando la clase `Process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd4ac3-2173-4bb0-b562-fac4cdfd9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "class Proceso_independiente(Process):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Mi n√∫mero:\", self.num, \"\\nMe voy a dormir 10s üí§üò¥üí§\")\n",
    "        time.sleep(10)\n",
    "        print(\"Despert√© üòÉ\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd5b0221-969c-4492-9b07-7661039808f0",
   "metadata": {},
   "source": [
    "Para utilizar el proceso se instancia un objeto de la clase `Proceso_ind` y se llama el m√©todo `.start()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fade8-f0fd-467c-83f3-43c5c49ceff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(5)\n",
    "proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a74157",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(10)\n",
    "proc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc1786-2251-4309-b320-4574b2aa1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"¬ø¬ø¬øü§®??? Me puedo ejecutar sin esperar a que la celda anterior termine\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7677086-a786-4646-970a-a3b7ac42aed2",
   "metadata": {},
   "source": [
    "**Obs**:En el ejemplo anterior, no fue necesario utilizar el metodo anulado `.run()`, este es llamado por `.start()` de manera interna."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f6749c-98fe-4c5e-9a3b-97fba4930c0c",
   "metadata": {},
   "source": [
    "En el caso en que se requiera esperar la finalizaci√≥n de un conjunto de tareas paralelas para luego recopilar resultados, es posible utilizar el m√©todo `.join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348451f-608a-4413-93e8-b7ef07efcd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_independiente(5)\n",
    "proc.start()\n",
    "proc.join()\n",
    "\n",
    "print(\"Aqu√≠ tuve que esperar üòî\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f059a32b-0282-47d6-ae4c-17bb55e55797",
   "metadata": {},
   "source": [
    "Con la construcci√≥n actual, es posible levantar tantos procesos como se requiera, en esta caso se levantan 3 procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6291f45-dd9b-42d2-8914-9ef2f2910828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "class Proceso_independiente(Process):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Me voy a dormir 10s ({self.num})üí§üò¥üí§\\n\")\n",
    "        time.sleep(10)\n",
    "        print(f\"Despert√© ({self.num})üòÉ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d4e5-608d-414c-8661-8d8fab839287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los 3 procesos\n",
    "procesos = (\n",
    "    Proceso_independiente(1),\n",
    "    Proceso_independiente(2),\n",
    "    Proceso_independiente(3),\n",
    ")\n",
    "\n",
    "# Se mide el tiempo de ejecucion\n",
    "start = time.time()\n",
    "\n",
    "# Iniciar todos los procesos\n",
    "for p in procesos:\n",
    "    p.start()\n",
    "\n",
    "# Esperar a que terminen todos los procesos\n",
    "for p in procesos:\n",
    "    p.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(\"Tiempo de ejecuci√≥n: \", end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1dde08-944a-4e67-a7f6-babd722394eb",
   "metadata": {},
   "source": [
    "Estos tres procesos corren de manera paralela, pues su tiempo de ejecuci√≥n total es aproximado al tiempo de ejecuci√≥n individual. \n",
    "\n",
    "Es necesario comprender que el orden de ejecuci√≥n de procesos paralelos no es necesariamente ordenando y predecible pues depende de c√≥mo el sistema operativo asigne los recursos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cca43fc-fc3d-4892-b2e1-69334c45e3e3",
   "metadata": {},
   "source": [
    "### Memoria Compartida y Dataraces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5609dfb8-e765-4b07-99be-dea9d5810189",
   "metadata": {},
   "source": [
    "Un data race es una situaci√≥n que ocurre cuando uno o m√°s hilos acceden concurrentemente a una posici√≥n de memoria o variable, al menos uno est√° escribiendo y al menos uno no est√° sincronizado con los otros hilos.\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/datarace_1.png' width=400/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Ejecuci√≥n secuencial en memoria compartida por threads.\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Race_condition'>Wikipedia</a>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/datarace_2.png' width=400/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "    Ejecuci√≥n paralela en memoria compartida por threads.\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Race_condition'>Wikipedia</a>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "**La soluci√≥n es tener mecanismos de sincronizaci√≥n** de hilos. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f980ca12",
   "metadata": {},
   "source": [
    "\n",
    "### Ejemplo en `multiprocessing`\n",
    "\n",
    "\n",
    "El comportamiento predeterminado de `multiprocessing` es generar procesos con memoria independiente, sin embargo, permite definir ciertas variables en memoria compartida. Para definir una variable en memoria compartida se utiliza la clase `Value`, a esta clase se le entrega un tipo de dato que puede ser `i` para entero, `f` para flotante, `d` para doble precisi√≥n entre otros. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b3fc9-1a31-40ff-bb87-cfc9e50efbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value\n",
    "\n",
    "comp_var = Value(\"d\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fe738b8-f485-4f52-a5ac-c14f81b020a6",
   "metadata": {},
   "source": [
    "Al utilizar variables en memoria compartida se deben tener en cuenta los procesos que acceden a ella, manejando la *concurrencia*, es decir, si los procesos pueden acceder a dichas variables de manera simultanea u ordenada. Por lo general en la actualizaci√≥n de valores unidimensionales se debe tener en cuenta la concurrencia bloqueando el acceso simultaneo. En arreglos se puede permitir tal manipulaci√≥n siempre que los computos sean independientes. \n",
    "\n",
    "Para bloquear el acceso a una variable compartida se hace uso de la clase `Lock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbefb31-c9e2-46ea-a054-6bac2611b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Lock\n",
    "\n",
    "lock = Lock()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a221d22-717b-405f-8b9d-7ff586f5b8d0",
   "metadata": {},
   "source": [
    "A continuaci√≥n se genera una rutina que accede a una variable de memoria compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2453437-182a-4b31-87e2-5c645e3ce596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value\n",
    "\n",
    "\n",
    "class Process_shared(Process):\n",
    "    def __init__(self, var, n=10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            self.var.value += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2ba6b92-367f-434b-afe9-2e176e7d97fe",
   "metadata": {},
   "source": [
    "El proceso asociado toma un valor y le a√±ade 1 hasta `n = 10000` veces por proceso. Se crea el valor inicial y se inicializan 3 procesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8056121-d6c1-4dd2-b007-2cdc2fb4e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value(\"i\")\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared(var) for i in range(3)]\n",
    "\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "\n",
    "    print(var.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc65807e-50a7-4929-abe3-e55643f61964",
   "metadata": {},
   "source": [
    "Se prueba el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f723ea8-06a4-49c2-a379-bbe4bd1b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6bc4ec-fd1a-45d4-9792-b60be221382c",
   "metadata": {},
   "source": [
    "Como se puede ver, el resultado no es necesariamente 30.000, esto se debe al acceso simultaneo y aleatorio de los procesos a `var`, para solucionar este problema se hace uso de `lock`, para ello se redefine la clase `Process_shared` observando que lock es un *context manager*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cb69d-18c7-41da-a0bd-d51f2b06a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process_shared_lock(Process):\n",
    "    def __init__(self, var, n=10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            with lock:\n",
    "                self.var.value += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "863e887a-0d1a-469d-86cd-11ed086ceba2",
   "metadata": {},
   "source": [
    "Se redefine la prueba asociada y se ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964469f-ee69-45b2-a6d1-def3de8097b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value(\"i\")\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared_lock(var) for i in range(3)]\n",
    "\n",
    "    [p.start() for p in procs]\n",
    "    [p.join() for p in procs]\n",
    "\n",
    "    print(var.value)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b281fb5-b9e4-45d8-a955-32e186044360",
   "metadata": {},
   "source": [
    "Con lo cual se obtiene el resultado buscado.\n",
    "\n",
    "Sin embargo, coordinar procesos m√°s complejos se torna tedioso y complejo, adem√°s de ser susceptible a errores.\n",
    "Por lo general, se recomienda, a menos que sea estrictamente necesario, a librer√≠as que facilitan la paralelizaci√≥n, como las que vamos a ver a continuaci√≥n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4fd2cfa-56e9-4c08-94de-5138b94c4903",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Paralelizaci√≥n con `Joblib`\n",
    "\n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/joblib.png' width=200>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71e8875-84aa-4168-be0a-1620404aeb79",
   "metadata": {},
   "source": [
    "Otra forma de paralelizar de forma relativamente sencilla es usar la librer√≠a `joblib`. \n",
    "Esta permite ejecutar funciones de forma paralela, pero ahora de manera funcional. \n",
    "Es decir, le entregamos una funci√≥n y una lista de argumentos y ejecuta una funci√≥n con dichos argumentos de forma paralela.\n",
    "\n",
    "Para esto, utiliza el decorador `delayed` sobre una funci√≥n (lo que la transforma a lazy, es decir, no se ejecuta instantaneamente). Luego a trav√©s del objeto `Parallel` que toma el n√∫mero de trabajos concurrentes que se ejecutar√°n (`n_jobs`) ejecuta las funciones con sus par√°metros.\n",
    "\n",
    "El siguiente ejemplo veremos como paralelizar el c√°lculo de coseno sobre una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "[np.cos(i) for i in np.arange(0, 1, 0.1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e750fb3d-fa80-4513-8e14-b8d4b36fdd07",
   "metadata": {},
   "source": [
    "La notaci√≥n es muy similar a un list comprehension, solo que con 2 diferencias:\n",
    "\n",
    "- Se reemplazan los corchetes exteriores `[f(i) for i in ...]` por par√©ntesis `(f(i) for i in ...)` (Esto da lugar a un generador en vez de una lista).\n",
    "- Se encapsula la funci√≥n a aplicar a cada elemento con la funci√≥n `delayed`, o sea, `f(i)` por `delayed(f)(i)`.\n",
    "\n",
    "Luego, lo anterior se le pasa como argumento a un Parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cbecb-4af7-49a3-b2a4-45a135ffdc53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# n_jobs=-1 indica que se usar√°n todos los procesadores disponibles.\n",
    "Parallel(n_jobs=-1)(delayed(np.cos)(i) for i in np.arange(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38219e2-b33b-4617-bf45-b1262227b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [np.cos(i) for i in np.arange(0, 1, 0.001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208c066-037e-4fd9-900b-3108705ed30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Parallel(n_jobs=-1)(delayed(np.cos)(i) for i in np.arange(0, 1, 0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81d8db37-d68c-48f9-8506-230171f86419",
   "metadata": {},
   "source": [
    "Para tareas num√©ricas no es tan efectivo (ya existe un cierto overhead/coste de generar los subprocesos), pero para tareas pesadas, se comporta bastante bien.\n",
    "\n",
    "Para este ejemplo, leeremos 50 veces archivo con n√∫meros aleatorios en forma secuencial y en forma paralelizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f773-c677-4d91-b93b-b2fb53e56265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def leer_archivo(_):\n",
    "    _ = pd.read_csv(\"https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo//num_aleatorios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d798fa4-8f7b-4619-9cc7-cc07f83c8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [leer_archivo(_) for _ in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81e619-afc1-4d05-9496-496dc0bc96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Parallel(n_jobs=-1)(delayed(leer_archivo)(_) for _ in range(0, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a56343c1-9281-463c-aa34-85ae685c7d78",
   "metadata": {},
   "source": [
    "Ahora si notamos diferencias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "504f4ce9",
   "metadata": {},
   "source": [
    "### Asincron√≠a y Corrutinas\n",
    "\n",
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/corrutinas.png' />\n",
    "</center>\n",
    "\n",
    "En general, se utiliza m√°s en el desarrollo web/software para no bloquear la ejecuci√≥n de c√≥digo al solicitar datos a un servidor externo o ejecutar un proceso muy pesado.\n",
    "\n",
    "\n",
    "> **Pregunta ‚ùì**: ¬øQu√© aplicaci√≥n de data science podr√≠a beneficiarse de la asincron√≠a?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d4bd170-c9bb-4d5e-b583-7ed801352710",
   "metadata": {},
   "source": [
    "## Procesamiento Distribuido\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/distributed.png'/>\n",
    "\n",
    "El procesamiento distribuido hace referencia a la ejecuci√≥n de tareas utilizando m√∫ltiples m√°quinas. Por lo general se refiere al trabajo con clusters de procesamiento y suele llevarse a cabo por medio de herramientas como [`Spark`](https://spark.apache.org/) o [`Dask`](https://www.dask.org/).\n",
    "\n",
    "Diferencias entre spark y dask: https://docs.dask.org/en/stable/spark.html\n",
    "\n",
    "En esta √∫ltima secci√≥n estudiaremos `Dask` para procesar `DataFrames`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "953daa93-b98e-4c50-b982-f6304fc349d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### `Dask`\n",
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask.jpg' width=300>\n",
    "</div>\n",
    "\n",
    "Dask permite escalar procesos de Python (ya sea en un computador personal o un cluster) de manera sencilla. Provee de funcionalidades para tratar, por medio de procesamiento multi-core, con datsets masivos **que por lo general no caben en memoria.**\n",
    "\n",
    "`Dask` fue implementado como un reemplazo de `Numpy` y `Pandas`, por ende su interfaz de usuario (API) es muy similar.\n",
    "Los `DataFrames` de Dask son en t√©rminos pr√°cticos conjuntos de `DataFrames` de pandas. Dicha separaci√≥n permite ejecutar operaciones distribuidas y paralelas de forma muy eficiente.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc063679-0fd9-4dfb-8d8f-3bff133be931",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask.png' width=600 />\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b93ab7d-4229-4bed-b651-3ddef71fa735",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='https://raw.githubusercontent.com/MDS7202/MDS7202/main/recursos/2023-01/23_compilacion_y_paralelismo/dask_mimic.png' width=700>\n",
    "</center>\n",
    "\n",
    "Pueden encontrar mayor informaci√≥n en la p√°gina oficial del proyecto:\n",
    "\n",
    "https://docs.dask.org/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3df70b-d038-4f3f-ad45-74d020c0912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"dask[dataframe]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3eb2393f-07ee-46fc-adfb-83649a5998bf",
   "metadata": {},
   "source": [
    "#### Pandas vs Dask\n",
    "\n",
    "##### Datos aleatorios con `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989eb50-a3c6-4aa4-9bb4-c1da1507b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generamos datos aleatorios (disminuir en caso de no contar con suficiente memoria)\n",
    "df = pd.DataFrame(np.random.random((2000000,200)))\n",
    "\n",
    "# generamos categor√≠as a partir de bins para luego agregar\n",
    "df[0] = pd.cut(df[0], 20)\n",
    "df[1] = pd.cut(df[1], 20)\n",
    "df[2] = pd.cut(df[2], 20)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6143e812-d647-468e-a00d-f5cea0765f57",
   "metadata": {},
   "source": [
    "La prueba ser√° cuanto se demora en ejecutar un `groupby(..).mean()` sobre las categor√≠as generadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9864d-520e-42ef-b1e3-53b28835cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04a5f91f-6b28-41d0-943f-c6603889662d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Inicializar `dask.dataframe`\n",
    "\n",
    "Ahora, generamos un `Dask DataFrame` desde pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94000af2-a0a1-480d-908e-5b2cfed041a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "ddf = dd.from_pandas(df, npartitions=5)\n",
    "ddf.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b443731-d353-49ba-8906-f4314577865e",
   "metadata": {},
   "source": [
    "Vemamos que pasa si hacemos la misma operaci√≥n que antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924b7ea-1e82-4ffc-9777-3eb00a525112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fba052b2-d9b1-4f7d-8087-986e736dd9e9",
   "metadata": {},
   "source": [
    "No produjo ning√∫n resultados. Esto es porque Dask es **Lazy**, es decir, se ejecuta solo cuando alguien demanda su ejecuci√≥n.\n",
    "Esto se puede lograr a partir del m√©todo `compute()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cb0c3-8fde-4f5e-a3b7-af10579cfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58719505-814a-41a9-94ab-be72d916b725",
   "metadata": {},
   "source": [
    "Incluso se puede visualizar como se computa la operaci√≥n distribuida a trav√©s de el siguiente m√©todo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13ac23-d602-4a70-8ee1-8e5f9c717d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby([0, 1, 2]).mean().visualize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2280461-9e3c-424d-b00b-d2f5b983928d",
   "metadata": {},
   "source": [
    "##### Comparaci√≥n de tiempos\n",
    "\n",
    "En las siguientes celdas ejecutamos al comparaci√≥n de tiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70538bc-d5e6-4068-833b-4bbe21de2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab1e67-9cd0-4780-95b8-ab13d76f6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ddf.groupby([0, 1, 2]).mean().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da8369a5-5997-44c9-ba8f-0f75d7345d78",
   "metadata": {},
   "source": [
    "Podemos ver que **Dask** no es m√°s r√°pido que **pandas** para la cantidad de datos anterior `(500000 x 200) ~ 752.9 MB`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e09b08da-7a4c-4392-b922-cc512377e874",
   "metadata": {},
   "source": [
    "Nuevamente, esto se debe al overhead / gasto adicional que implica lanzar varios procesos para ejecutar tareas en paralelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468488b0",
   "metadata": {},
   "source": [
    "## Polars\n",
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg\" width=450>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "Blazingly Fast DataFrame Library \n",
    "</div>\n",
    "\n",
    "Nueva librer√≠a alternativa a pandas enfocada en alto rendimiento y programado √≠ntegramente en [Rust](https://www.rust-lang.org/es).\n",
    "\n",
    "Sus principios son:\n",
    "\n",
    "- **R√°pido**: Polars est√° escrito desde cero, dise√±ado cerca de la m√°quina y sin dependencias externas.\n",
    "- **E/S**: Soporte para todas las capas comunes de almacenamiento de datos: local, almacenamiento en la nube y bases de datos.\n",
    "- **F√°cil de usar**: Escriba sus consultas de la forma en que fueron concebidas. Polars, internamente, determinar√° la forma m√°s eficiente de ejecutar utilizando su optimizador de consultas.\n",
    "- **_Out of core_**: Polars soporta la transformaci√≥n de datos fuera del n√∫cleo con su API de streaming. Permiti√©ndole procesar sus resultados sin requerir que todos sus datos est√©n en memoria al mismo tiempo.\n",
    "- **Paralelo**: Polars utiliza plenamente la potencia de su m√°quina dividiendo la carga de trabajo entre los n√∫cleos de CPU disponibles sin ninguna configuraci√≥n adicional.\n",
    "- **Motor de consulta vectorizado**: Polars utiliza Apache Arrow, un formato de datos en columnas, para procesar sus consultas de forma vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acada1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3dd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl_df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_df.groupby([0, 1, 2]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85dfb1d9-164a-466a-ac04-c67e84618a40",
   "metadata": {},
   "source": [
    "### Debo usar estos frameworks?\n",
    "\n",
    "Si tu dataset cabe en memoria comodamente y no es muy grande, entonces no es necesario usar `Dask`. Simplemente agregar√° una capa de complejidad al desarrollo.\n",
    "\n",
    "Por otra parte, si el dataset con el cu√°l est√°n trabajando es masivo, entonces dichas librer√≠as son un buen factor a considerar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb25b97",
   "metadata": {},
   "source": [
    "## Y para usar la GPU?\n",
    "\n",
    "Pueden utilizar estas alternativas:\n",
    "\n",
    "- [Cupy](https://docs.cupy.dev/en/stable/user_guide/basic.html) - Implementaci√≥n de `NumPy/SciPy` usando `CUDA` (para GPUs nvidia)\n",
    "- [Rapids](https://rapids.ai/start.html): Colecci√≥n de librer√≠as basadas en `CUDA` que al igual que la alternativa anterior, mejora el rendimiento a trav√©s de la GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
