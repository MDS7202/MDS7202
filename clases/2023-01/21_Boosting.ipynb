{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97e3ccc-bc09-45f0-bfe8-1c9934f802a0",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines (GBM)\n",
    "\n",
    "las maquinas de gradient boosting son algoritmos que se volvieron muy populares con la aparición de XGBoost en el 2016 para las tareas de clasificación y regresión. En términos de funcionamiento, estos algoritmos utilizan multiples \"weak-learners\" con los que a través de multiples iteraciones corrigen los errores que presentan sus regresores/clasificadores en etapas anteriores.\n",
    "\n",
    "\t\t❓ Pregunta: ¿Que caracteristicas tienen los \"weak-learners\"?\n",
    "\n",
    ">> 1.  El objetivo no es crear clasificadores potentes con ellos, si no como su nombre lo dice queremos generar \"aprendices débiles\" que se potencien con otros.\n",
    ">> 2. En general se utilizan como weak learners arboles de decisión por su simpleza y versatilidad que nos ofrecen para regresión y clasificación.\n",
    ">> 3. Pueden ser entrenados con una muestra de la totalidad para obtener entrenamientos rápidos sobre ellos.\n",
    ">> 4. Su uso en un algoritmo implica la comprensión de estos elementos, ya que se heredan sus problemas en una estructura mas compleja.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef55d0-679c-40f4-93fc-d861ad65f08d",
   "metadata": {},
   "source": [
    "❓ Pregunta: ¿Que problemas tenian los arboles de decisión?\n",
    "![3 Techniques to Avoid Overfitting of Decision Trees | by Satyam Kumar |  Towards Data Science](https://miro.medium.com/v2/resize:fit:1702/1*KbRVJC5B0EgO8YAyeCrLkA.png)\n",
    "\n",
    "Recordar que los árboles de decisión son elementos que tienen una alta facilidad de sobre-ajustarse si aumentamos la profundidad o número de hijos por nodo. Esto puede causar problemas en un algoritmo de GBM y por ello, este debe ser un valor que debemos controlar de forma directa o indirectamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42f5ff-80b5-490a-924e-5fef5dfc8102",
   "metadata": {},
   "source": [
    "Adentrándonos mas en detalles en el algoritmo de gradient boosting, estos forman parte de los algoritmos de ensemble, quienes basicamente son algoritmos que combinan multiples modelos para el proceso de predicción. Una forma de esto es a traves de modelos aditivos, donde entrenando multiples algoritmos simples de forma independiente, utilizamos la suma de sus salidas para generar un modelo mas potente para la regresión/clasificación:\n",
    "$$F_M(x) = f_1(x)+...+f_M(x)=\\sum_{m=1}^M f_m(x)$$\n",
    "![Develop an Intuition for How Ensemble Learning Works -  MachineLearningMastery.com](https://machinelearningmastery.com/wp-content/uploads/2020/07/Example-of-Combining-Decision-Boundaries-Using-an-Ensemble.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e28f15-95f2-4125-87f6-bdfa13312dc2",
   "metadata": {},
   "source": [
    "### GBM: Regresión\n",
    "\n",
    "La idea que sigue por detras las GBM es realizar descenso del gradiente a una función $\\hat{f}$ en el espacio de funciones. O sea, si utilizamos un conjunto $f$ de funciones deseamos disminuir, todo lo posible la función de error que representa la función de perdida ($\\mathcal{L}$) durante el entrenamiento. Formalmente:\t\n",
    "$$\\hat{f}=argmin_f \\, \\mathcal{L}(f)$$\n",
    "donde $f$:\n",
    "$$f = (f(x_1), ..., f(x_N))$$\n",
    "Donde en cada paso $m$ (número de la iteración) generaremos un gradiente $g_m$ de la función $\\mathcal{L(f_m)}$ :\n",
    "$$g_m = [\\dfrac{\\partial{l}(y_i,f(x_i))}{\\partial{f}(x_i)}]_{f=f_{m-1}}$$\n",
    "En cada una de las iteraciones del modelo $g_m$ se encargara de actualizar el valor de $f_{m-1}$, de tal forma de generar la función $f_m$ de la iteración. $g_m$ es la expresión matematica que contiene la información de los errores de la predicción anterior que deseamos corregir en cada iteración. \n",
    "\n",
    "Luego, para comprender la actualización situémonos en el paso $m$, en el tendremos:\n",
    "$$f_m = f_{m-1} - \\beta_{m}g_{m}$$\n",
    "Donde $\\beta_m$ se define como el largo del paso en la corrección. Visto de otra forma, podemos interpretar esta valor como un factor de aprendizaje que podremos fijar o optimizar en la función, señalando cuanta corrección aplicaremos del proceso anterior en el proceso actual. \n",
    "\n",
    "Si bien en cada una de las iteraciones encontraremos un valor optimo para $f_m$ y $N$ puntos, esta por si sola no genera un clasificador global capaz de obtener mejores generalizaciones, por esta razón necesitamos definir una nueva función con la misma idea pero que en cada iteración se haga mas robusta. En esta modificación, el algoritmo para ajustar los weak-learners a una aproximación de la señal negativa del gradiente, donde en cada iteración entrenara un nuevo weak learner, quedando la actualización de la función como:\n",
    "$$F_m = argmin_F \\sum_{i=1}^N (-g_{im}-F(x_i))^2$$\n",
    "Notar que $F(x_i)$ es un weak learner que se entrena en cada una de las iteraciones de nuestro algoritmo de GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106ab54-77ce-4806-994c-7a4dc0020537",
   "metadata": {},
   "source": [
    "Finalmente el algoritmo se vería como:\n",
    "\n",
    "![](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-01/21_Ensamblaje/Pasted%20image%2020230527153450.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceffe09-45a9-4009-9131-c5f0c4a260b6",
   "metadata": {},
   "source": [
    "### GBM: Clasificación\n",
    "\n",
    "\t\t❓ Pregunta: ¿Debería ser diferente la clasificación a la regresión?\n",
    "\n",
    "La respuesta directa a esto es \"sí\". Los cambios que presenta la clasificación respecto a la regresión se dan netamente en la elección de la función de perdida ($\\mathcal{L}$) y algunas consideraciones que se toman para las salidas de los nodos.\n",
    "\n",
    "Respecto a las funciones de perdida, esto se debe a como se define el problema de clasificación supervisada, donde nuestro interés no será la reducción el error que tenemos del valor estimado respecto a un valor continuo. En su reemplazo son utilizadas funciones de perdida para clasificación, quienes tienen como principal objetivo disminuir el error predecir una etiqueta. Una de las funciones de perdidas mas conocidas/utilizadas para el problema de clasificación se encuentra la logistic-loss/cross-entropy:\n",
    "$$\\mathcal{L}_i = -(y_i log(p_i) + (1-y_i)log(1-p_i))$$\n",
    "\t❓ Pregunta:  ¿Como podemos interpretar esta función de perdida?\n",
    "\t\n",
    "Donde su derivada es:\n",
    "$$\\dfrac{\\partial \\mathcal{L}_i}{\\partial \\hat{y}}=p_i-y_i$$\n",
    "El segundo punto a considerar es que la estimación de $y$ sera igual a:\n",
    "$$\\hat{y}=log(odds)=log(\\dfrac{p}{1-p})$$\n",
    "\t\t❓ Pregunta:  ¿Por que usamos odds?\n",
    "\t\t\n",
    "Básicamente debido a que los modelos de clasificación con GBM son modelos de regresión, por lo que sus salidas no pueden ser consideradas como probabilidades, sino como scores que debemos transformar y normalizar.\n",
    "\n",
    "Finalmente para calcular las probabilidades de las salidas de nuestro GBM tendremos que calcular la función softmax de $\\hat{y}$, la que viene dada por:\n",
    "$$\\text{softmax}(\\hat{y})=\\dfrac{1}{1+e^{-\\hat{y}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9a3d69-63da-47bc-8468-c5517cec4274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.605170185988091"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "p = 0.99\n",
    "y = 0\n",
    "-(y*math.log(p)+(1-y)*math.log(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63d66a4-9905-40d6-9501-4b58f59d469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10536051565782628"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.9\n",
    "y = 1\n",
    "-(y* math.log(p) + (1-y)*math.log(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f36f6af-cde4-4944-b2c8-07b2df783e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.3\n",
    "y = 0\n",
    "-(y* math.log(p) + (1-y)*math.log(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35087c5c-1382-4698-bfc5-b28334ea2811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.1,
          0.2,
          0.3,
          0.4,
          0.5,
          0.6,
          0.7,
          0.8,
          0.9
         ],
         "xaxis": "x",
         "y": [
          2.3025850929940455,
          1.6094379124341003,
          1.2039728043259361,
          0.916290731874155,
          0.6931471805599453,
          0.5108256237659907,
          0.35667494393873245,
          0.2231435513142097,
          0.10536051565782628
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss with different predictions: y=1"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0.1,
          0.9
         ],
         "title": {
          "text": "x"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.016707516416408108,
          2.42465312506828
         ],
         "title": {
          "text": "y"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"c8808a91-1cec-4142-a848-04658fe7a861\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c8808a91-1cec-4142-a848-04658fe7a861\")) {                    Plotly.newPlot(                        \"c8808a91-1cec-4142-a848-04658fe7a861\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"xaxis\":\"x\",\"y\":[2.3025850929940455,1.6094379124341003,1.2039728043259361,0.916290731874155,0.6931471805599453,0.5108256237659907,0.35667494393873245,0.2231435513142097,0.10536051565782628],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Loss with different predictions: y=1\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c8808a91-1cec-4142-a848-04658fe7a861');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lis1, prob = [], []\n",
    "for i in range(1, 10):\n",
    "    y = 1\n",
    "    lis1.append(-(y* math.log(i/10) + (1-y)*math.log(1-i/10)))\n",
    "    prob.append(i/10)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "px.line(x=prob, y=lis1, title=f'Loss with different predictions: y={y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753bb7e-4280-47c2-bae5-c3990a0ad0b9",
   "metadata": {},
   "source": [
    "### Retrospectiva\n",
    "\n",
    "\t\t❓ Pregunta: ¿Pero como podriamos simplificar estas definiciones que acabamos de dar?\n",
    "\n",
    "Si visualizamos GBM en un juego de golf, tendriamos un jugador que comienza con un tiro $f_0$, el cual a medida que va realizando cada tiro va aplicando una corrección $\\Delta_m$ en cada una de sus jugadas. Con esto, si cerebralmente el jugador corrigue sus errores a traves de una función MSE, tendremos que el jugador ira optimizando esta función hasta meter la pelota en el agujero (minimo de la función de perdida).\n",
    "\n",
    "$\\text{MSE LOSS} = \\mathcal{L}(y, F_M(X))=\\dfrac{1}{N} \\sum_{i=1}^N (y_i - F_M(x_i))^2$\n",
    "\n",
    "![](https://explained.ai/gradient-boosting/images/golf-MSE.png)\n",
    "\n",
    "\t\t❓ ¿Como podría el golfista correguir de mejor forma sus tiros? ¿existe alguna forma?.\n",
    "\t\t\n",
    "![1d-vectors.png](https://explained.ai/gradient-boosting/images/1d-vectors.png)\n",
    "\n",
    "Como vimos durante el entrenamiento de GBM, este proceso considera un $\\nu$ conocido como shrinkage rate o learning rate. Este valor nos permitirá realizar correcciones en las actualizaciones de nuestras funciones $f_m$, ya que podría darse el caso que el gradiente obtenido durante la optimización sea muy alto y nos permita obtener un minimo adecuado para el problema. De esta forma:\n",
    "$$f_m(x) = f_{m-1}(x) + \\nu F_m(x)$$\n",
    "Otra forma podría ser cambiando la función de perdida que definimos en el problema. Dependiendo si es un problema de clasificación o regresión existen multiples funciones de perdida con diferentes interpretaciones que pueden mejor significativamente el problema que deseamos resolver. Algunas de estas son:\n",
    "\n",
    "| Nombre         | Loss                         | Derivada           |  \n",
    "| -------------- | ---------------------------- | ------------------ |\n",
    "| Squeared Error | $\\dfrac{1}{2}(y_i-f(x_i))^2$ | $y_i -f(x_i)$      |\n",
    "| Absolute Error | $y_i - f(x_i)$               | $sgn(y_i -f(x_i))$ |\n",
    "| Binary Logloss                | $log(1+e^{-y_if_i})$  | $y-\\sigma(2f(x_i))$    |\n",
    "\n",
    "\n",
    "En tercer lugar tenemos la adición de un regularizador a nuestra función de perdida, de esta forma podremos disminuir el sobreajuste de nuestro modelo, generando pequeñas modificaciones en los arboles que vamos generando.\n",
    "$$\\mathcal{L}(f) = \\sum_{i=1}^Nl(y_i,f(x))+\\Omega(f))$$\n",
    "donde $\\Omega$:\n",
    "$$\\Omega(f)= \\gamma J+\\dfrac{1}{2}\\lambda \\sum_{j=1}^J w^2_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b7e14-270b-4467-924a-10189151b12d",
   "metadata": {},
   "source": [
    "### Pros & Cons\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "- Capacidad para manejar tanto problemas de regresión como de clasificación.\n",
    "- Puede capturar relaciones no lineales y características complejas en los datos.\n",
    "- Adaptabilidad a diferentes tipos de predictores, incluyendo variables numéricas y categóricas.\n",
    "- Robustez ante valores atípicos y datos ruidosos.\n",
    "- Capacidad para manejar grandes conjuntos de datos y escalabilidad.\n",
    "- Flexibilidad en la elección de funciones de pérdida y métricas de evaluación.\n",
    "- Capacidad para manejar características faltantes y utilizar todas las observaciones disponibles.\n",
    "- Puede generar importancia de variables para ayudar en la interpretación y selección de características.\n",
    "\n",
    "**Contras**:\n",
    "\n",
    "- Mayor complejidad y tiempo de entrenamiento en comparación con algoritmos más simples.\n",
    "- Puede ser propenso a sobreajuste si no se controlan los hiperparámetros adecuadamente.\n",
    "- Requiere una configuración cuidadosa de los hiperparámetros para obtener el mejor rendimiento.\n",
    "- Interpretación más difícil debido a la naturaleza de combinación de múltiples árboles.\n",
    "- Sensible a datos desequilibrados, donde las clases minoritarias pueden no recibir suficiente atención.\n",
    "- La importancia de las variables puede verse sesgada hacia las variables numéricas o con mayor cardinalidad.\n",
    "- No es adecuado para problemas con alta dimensionalidad o con muchos predictores.\n",
    "- Mayor consumo de recursos computacionales en comparación con algoritmos más simples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac118e-ce1c-438a-891d-ea51090f5278",
   "metadata": {},
   "source": [
    "## Ejemplo a Mano 🤨\n",
    "\n",
    "Como ya sabemos como funciona port detras un algoritmo simple de Gradient Boosting, veamos un ejemplo para ejecutar un pequeño GBM a mano. Para esto consideremos los siguientes datos:\n",
    "\n",
    "| index | $feature_1$ | $feature_2$ | y     |  \n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1     | 1.12  | 1.4   | 1     |   \n",
    "| 2     | 5.45  | 3.1   | 0     |   \n",
    "| 3     | 3.54  | 1.2   | 1     |   \n",
    "\n",
    "Considerando los datos construir un modelo de GBM con 2 estimadores y un $\\nu$ igual a $0.1$.\n",
    "\n",
    "**Desarrollo:**\n",
    "Con la tabla anterior, comenzamos realizando nuestra primera iteración (m=1), para ello se considera que todos los datos se encuentran en el mismo nodo. De esta forma, calculando los odds y los log(odds) de los datos tendremos:\n",
    "\n",
    "$$odds = \\dfrac{\\text{cantidad de casos exitosos}}{\\text{cantidad de casos fallidos}}$$\n",
    "$$odds = 2/1 = 2$$\n",
    "Luego para los $log_n(odds)$:\n",
    "$$log_n(odds)=log_n(2)=0,693$$\n",
    "Notar que debido a que todos los valores estan en el mismo nodo, todos los valores poseeran el mismo log_n(odds). Luego calculamos las probabilidades para cada uno de los valores.\n",
    "$$p=\\dfrac{1}{1+e^{-\\hat{y}}}=\\dfrac{1}{1+e^{-0.693}}=0.67$$\n",
    "Finalmente $\\gamma$ sera:\n",
    "$$\\gamma_1=y-p_1=1-0.67=0.33$$\n",
    "$$\\gamma_2=y-p_2=0-0.67=-0,67$$\n",
    "$$\\gamma_3=y-p_3=1-0.67=0.33$$\n",
    "Tenemos nuestro primer estimador calculado, ahora el siguiente paso es generar un nuevo árbol. Para esto vamos a generar un árbol donde el nodo padre tiene la regla $feature_2>2$.\n",
    "\n",
    "![](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-01/21_Ensamblaje/Flowchart%20Template.jpg?raw=true)\n",
    "\n",
    "Considerando los resultados obtenidos en la iteración anterior, tendremos que ahora los valores de $\\gamma_i$ estan dados por:\n",
    "$$\\gamma_{i}=\\dfrac{\\sum_i y_i-p_i}{\\sum_i p_i(1-p_i)}$$\n",
    "Reemplazando cada valor:\n",
    "$$\\gamma_{1m}=\\dfrac{0.33+0.33}{2*(0.67(1-0.67))}=1.49$$\n",
    "$$\\gamma_{2m}=\\dfrac{-0.67}{0.67(1-0.67)}=-3.03$$\n",
    "Finalmente, con los valores obtenidos calculamos el $F_m$ resultante de las 2 iteraciones para cada una de las hojas:\n",
    "\n",
    "$$F_m(x)=F_{m-1}(x)+\\nu \\gamma_m$$\n",
    "Reemplazamos para cada uno de los valores que tenemos por fila:\n",
    "$$\\hat{y_1}=F_1(x_1)=0.69+0.1*1.49=0.839$$\n",
    "$$\\hat{y_2}=F_2(x_2)=0.69+0.1*(-3.03)=0.387$$\n",
    "$$\\hat{y_3}=F_3(x_3)=0.69+0.1*1.49=0.839$$\n",
    "Como podemos ver, estos valores solamente representan un score que no nos indica la probabilidad, para esto aplicamos una softmax para normalizar las salidas:\n",
    "\n",
    "$$p_1=\\dfrac{1}{1+e^{-\\hat{y}}}=0.698$$\n",
    "$$p_2=0.595$$\n",
    "$$p_3=0.698$$\n",
    "Finalmente los residuales de cada una de las salidas es:\n",
    "\n",
    "$$\\gamma_1 = \\gamma_3 = 0.302$$\n",
    "$$\\gamma_2 = -0.595$$\n",
    "\t\t❓ Pregunta: ¿el calculo tiene una dependencia de las features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03c8ee-e596-49dc-991d-491c3f944c32",
   "metadata": {},
   "source": [
    "## Ejemplo con Código 🧐\n",
    "\n",
    "Como ya comprendimos que es un algoritmo de GBM de forma teorica y como este se calcula a mano, el ultimo paso es visualizar como funciona el entrenamiento a través de código. Para realizar este ejercicio codificaremos desde 0 el algoritmo de GBM utilizando los `DecisionTreeClassifier` de scikit-learn. \n",
    "\n",
    "**Objetivo:** Codificar cada una de las partes que contiene un algoritmo de GBM en una clase de python.\n",
    "\n",
    "![XGBoost vs LightGBM: How Are They Different](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Gradient-boosting-LightGBM-vs-XGBoost.png?resize=591%2C431&ssl=1)\n",
    "\n",
    "Comenzamos definiendo el inicializador de nuestra clase `GBMClassifier`, para esto definimos los siguientes valores:\n",
    "- n_estimators = Número de arboles que vamos a entrenar en el entrenamiento secuencial e iterativo.\n",
    "- max_depth = Maxima profundidad de los arboles que vamos a entrenar.\n",
    "- lr = Tasa de aprendizaje de nuestro GBM.\n",
    "- loss = Definimos la función de perdida que vamos a utilizar para el problema.\n",
    "\n",
    "```python\n",
    "class GBMClassifier:\n",
    "    def __init__(self, n_trees, learning_rate=0.1, max_depth=1, loss_function=None):\n",
    "            self.n_trees=n_trees\n",
    "            self.learning_rate=learning_rate\n",
    "            self.max_depth=max_depth\n",
    "            self.loss_function = loss_function\n",
    "```\n",
    "\n",
    "En segundo lugar debemos definir el método que entrenara a a nuestro modelo GBM. Para la construcción consideramos los siguientes pasos:  \n",
    "1. Generamos una lista donde almacenaremos nuestros arboles en cada una de las iteraciones, para esto generamos un atributo donde sera almacenado.\n",
    "2. En segundo lugar es necesario obtener obtener las predicciones bases de la primera etapa de nuestro modelo utilizando la función que calcula los gradientes de la función de perdida.\n",
    "3. Generamos un loop en el que entrenaremos los $n$ árboles que definimos al inicializar la GBM y realizamos los siguientes pasos.\n",
    "\t1. Obtener los gradientes ($\\gamma$) de cada una de las etapas.\n",
    "\t2. Entrenamos los árboles con los gradientes obtenidos en 1.\n",
    "\t3. Actualizamos las predicciones realizadas por nuestros árboles.\n",
    "\t4. Obtenemos $F_M$ a utilizando las predicciones y el learning rate.\n",
    "\t5. Agregamos el árbol entrenado en esta etapa a nuestra lista de árboles.\n",
    "\n",
    "```python \n",
    "def fit(self):\n",
    "self.trees = []\n",
    "        self.base_prediction = self._argmin_fun(y=y)\n",
    "        current_predictions = self.base_prediction * np.ones(shape=y.shape)\n",
    "        for _ in range(self.n_trees):\n",
    "            pseudo_residuals = self.loss_function.negative_gradient(y, current_predictions)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, pseudo_residuals)\n",
    "            self._update_terminal_nodes(tree, X, y, current_predictions)\n",
    "            current_predictions += self.learning_rate * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "```\n",
    "\n",
    "Para calcular los gradientes de nuestra función utilizaremos una función de minimización, de esta forma no nos preocuparemos de las derivadas. En la definición de este método tendremos dos casos: el caso base, cuando no se tiene un $\\hat{y}$ y un segundo cuando se tiene las predicciones de un estimador.\n",
    "\n",
    "```python\n",
    "def _argmin_fun(self, y, y_hat=None):\n",
    "        if np.array(y_hat).all() == None:\n",
    "            fun = lambda c: self.loss_function.loss(y, c)\n",
    "        else:\n",
    "            fun = lambda c: self.loss_function.loss(y, y_hat+c)\n",
    "        c0 = y.mean()\n",
    "        return minimize(fun=fun, x0=c0).x[0]\n",
    "```\n",
    "\n",
    "Finalmente tenemos la actualización de los nodos del árbol entrenado, para esto comenzamos obtenido las `ids` de los nodos que contienen las predicciones y los recorremos en un loop:\n",
    "\n",
    "1. Dentro del loop encontramos todos los valores que esten la misma hoja y seleccionamos los `y` e $\\hat{y}$ que poseen estos valores.\n",
    "2. Calculamos el $\\gamma$ de estos valores y reemplazamos en los árboles.\n",
    "\n",
    "```python\n",
    "def _update_terminal_nodes(self, tree, X, y, current_predictions):\n",
    "        leaf_nodes = np.nonzero(tree.tree_.children_left == -1)[0]\n",
    "        leaf_node_for_each_sample = tree.apply(X)\n",
    "        for leaf in leaf_nodes:\n",
    "            samples_in_this_leaf = np.where(leaf_node_for_each_sample == leaf)[0]\n",
    "            y_in_leaf = y.take(samples_in_this_leaf, axis=0)\n",
    "            preds_in_leaf = current_predictions.take(samples_in_this_leaf, axis=0)\n",
    "            val = self._argmin_fun(y=y_in_leaf, y_hat=preds_in_leaf)\n",
    "            tree.tree_.value[leaf, 0, 0] = val\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bc227-ecef-40fa-a0c4-e481915fe7b6",
   "metadata": {},
   "source": [
    "### Definamos la clase que creamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917a2ec-2322-4c76-9e06-1d92a6606339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class GradientBoostingMachine():\n",
    "    \n",
    "    def __init__(self, n_trees, learning_rate=0.1, max_depth=1, loss_function=None):\n",
    "        self.n_trees=n_trees\n",
    "        self.learning_rate=learning_rate\n",
    "        self.max_depth=max_depth\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def fit(self, X, y):        \n",
    "        self.trees = []\n",
    "        self.base_prediction = self._argmin_fun(y=y)\n",
    "        current_predictions = self.base_prediction * np.ones(shape=y.shape)\n",
    "        for _ in range(self.n_trees):\n",
    "            pseudo_residuals = self.loss_function.negative_gradient(y, current_predictions)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, pseudo_residuals)\n",
    "            self._update_terminal_nodes(tree, X, y, current_predictions)\n",
    "            current_predictions += self.learning_rate * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def _argmin_fun(self, y, y_hat=None):\n",
    "        if np.array(y_hat).all() == None:\n",
    "            fun = lambda c: self.loss_function.loss(y, c)\n",
    "        else:\n",
    "            fun = lambda c: self.loss_function.loss(y, y_hat+c)\n",
    "        c0 = y.mean()\n",
    "        return minimize(fun=fun, x0=c0).x[0]\n",
    "        \n",
    "    def _update_terminal_nodes(self, tree, X, y, current_predictions):\n",
    "        leaf_nodes = np.nonzero(tree.tree_.children_left == -1)[0]\n",
    "        leaf_node_for_each_sample = tree.apply(X)\n",
    "        for leaf in leaf_nodes:\n",
    "            samples_in_this_leaf = np.where(leaf_node_for_each_sample == leaf)[0]\n",
    "            y_in_leaf = y.take(samples_in_this_leaf, axis=0)\n",
    "            preds_in_leaf = current_predictions.take(samples_in_this_leaf, axis=0)\n",
    "            val = self._argmin_fun(y=y_in_leaf, y_hat=preds_in_leaf)\n",
    "            tree.tree_.value[leaf, 0, 0] = val\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return (self.base_prediction \n",
    "                + self.learning_rate \n",
    "                * np.sum([tree.predict(X) for tree in self.trees], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4732efd-d1e8-4fc1-8d20-71810335d08a",
   "metadata": {},
   "source": [
    "#### Probemos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed80534-1480-4ff3-9bdf-e87931701bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rng\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "\n",
    "# test data\n",
    "def make_test_data(n, noise_scale):\n",
    "    x = np.linspace(0, 10, 500).reshape(-1,1)\n",
    "    y = (np.where(x < 5, x, 5) + rng.normal(0, noise_scale, size=x.shape)).ravel()\n",
    "    return x, y\n",
    "    \n",
    "# print model loss scores\n",
    "def print_model_loss_scores(obj, y, preds, sk_preds):\n",
    "    print(f'From Scratch Loss = {obj.loss(y, pred):0.4}')\n",
    "    print(f'Scikit-Learn Loss = {obj.loss(y, sk_pred):0.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4578ab0-647c-4feb-ba15-5551f209c185",
   "metadata": {},
   "source": [
    "Comenzamos generando unos datos con cierto grado de relación para generar una regresión simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be632ae1-a6f8-414e-8a8a-0dad43952404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "x, y = make_test_data(500, 0.4)\n",
    "px.scatter(x, y, title='Datos de Prueba',template='simple_white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d222aa-b357-4842-954f-ca0dda66a48c",
   "metadata": {},
   "source": [
    "Donde nuestra función de perdida viene dada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbad0e-b303-4994-96f9-aef0afd3cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss():\n",
    "    '''User-Defined Squared Error Loss'''\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss(y, preds):\n",
    "        return np.mean((y - preds)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def negative_gradient(y, preds):\n",
    "        return y - preds\n",
    "    \n",
    "\n",
    "gbm = GradientBoostingMachine(n_trees=100,\n",
    "                                  learning_rate=0.5,\n",
    "                                  max_depth=1,\n",
    "                                  loss_function=MSELoss()\n",
    "                                 )\n",
    "gbm.fit(x, y)\n",
    "pred = gbm.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d96bfa-2f27-4074-ad8b-98473526ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fee02-f237-42be-91da-e9c7c8b7a24d",
   "metadata": {},
   "source": [
    "Con los datos generamos un loop para visualizar como es el impacto que los estimadores dentro de la regresión, con esto obtenemos los siguientes gráficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1416df-3aec-4512-bf19-773263b52bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_regresion(x, y, y_pred, name=\"Datos con regresión\", color='r'):\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, pred, color='r')\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(1, 11):\n",
    "    gbm = GradientBoostingMachine(n_trees=i,\n",
    "                                  learning_rate=0.5,\n",
    "                                  max_depth=1,\n",
    "                                  loss_function=MSELoss()\n",
    "                                 )\n",
    "    gbm.fit(x, y)\n",
    "    pred = gbm.predict(x)\n",
    "    name_plot = f\"Datos con regresión con {i} estimadores\"\n",
    "    plot_regresion(x, y, pred, name=name_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4dcfa-c425-4e73-9b0c-1c2a0620665a",
   "metadata": {},
   "source": [
    "Comprobemos si esto tiene sentido con el clasificador de boosting que viene en sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15c0b5-3418-4f66-b7b3-8292652f73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_gbm = GradientBoostingRegressor(n_estimators=10,\n",
    "                                   learning_rate=0.5,\n",
    "                                   max_depth=1)\n",
    "sk_gbm.fit(x, y)\n",
    "sk_pred = sk_gbm.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c525d-d947-4cf1-bdb8-aea91ecbc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_loss_scores(MSELoss(), y, pred, sk_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1649bf-b1be-47bd-b14a-b78cae35e035",
   "metadata": {},
   "source": [
    "De los resultados se observa que a medida que aumentamos el número de estimadores es posible generar una regresión más similar a la tendencia que señalan los datos, por lo que la adición de weak-learners a nuestro modelo fue efectivo!\n",
    "\n",
    "## Retrospectiva\n",
    "\n",
    "\t\t❓ Pregunta: ¿añadir muchos estimadores que puede provocar?\n",
    "\t\t❓ Pregunta: Sabemos que los árboles son interpretables, ¿que sucede con los algoritmos de ensemle?\n",
    "\t\t❓ Pregunta: ¿Comó podemos medir el sobre ajuste de estos modelos si son multiples árboles?\n",
    "\t\t❓ Pregunta: ¿A nivel general son buenos estimadores los GBM?\n",
    "\t\t\n",
    "\n",
    "Links de interes:\n",
    "https://explained.ai/gradient-boosting/descent.html\n",
    "https://www.cienciadedatos.net/documentos/py09_gradient_boosting_python.html\n",
    "https://explained.ai/gradient-boosting/L2-loss.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e9eed-8072-4479-9bfa-4faa156963e3",
   "metadata": {},
   "source": [
    "## Contenido Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2455263-d46b-450e-a86c-9574bdcf673c",
   "metadata": {},
   "source": [
    "### Qué es Monotonicity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce76ee5-2295-43e1-913b-cbbfb4d83657",
   "metadata": {},
   "source": [
    "Diferentes variaciones entre una característica X e Y se reconocen como una función no monótona, y podemos representar esto de la siguiente manera:\n",
    "\n",
    "![Imagen 1](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915081517.png?raw=true)\n",
    "\n",
    "Por otro lado, si la relación aumenta, tenemos una función monótonamente creciente:\n",
    "\n",
    "$$f(x_{1}, x_{2}, x, \\dots, x_{n}) \\geq f(x_{1}, x_{2}, x', \\dots, x_{n})$$\n",
    "\n",
    "![Imagen 2](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915081603.png?raw=true)\n",
    "\n",
    "Finalmente, otro caso es la función monótonamente decreciente, dada por una relación decreciente entre X e Y:\n",
    "\n",
    "$$f(x_{1}, x_{2}, x, \\dots, x_{n}) \\leq f(x_{1}, x_{2}, x', \\dots, x_{n})$$\n",
    "![Imagen 3](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915081659.png?raw=true)\n",
    "\n",
    "Matemáticamente, si podemos establecer restricciones que nos permitan generar una salida positiva o negativa para cada variable, esto nos permitirá generar un mejor modelo para el negocio.\n",
    "\n",
    "Estas son las ideas básicas que necesitamos comprender para saber cómo utilizar esto. El siguiente paso es definir cómo podemos obtener o visualizar el comportamiento monótono entre las variables (si no tenemos una idea clara de la relación). La mejor manera de hacerlo es mediante el uso de Gráficos de Dependencia Parcial (PDP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38d6cc-7b77-4484-9bd8-fae5ac7b8471",
   "metadata": {},
   "source": [
    "### Monotonicity in Models\n",
    "#### Motivation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a580d1-614a-49c0-94ea-5ac0ea01521e",
   "metadata": {},
   "source": [
    "Si conocemos la relación entre dos variables y el objetivo, deberíamos generar o ayudar al modelo a generar un modelo con este comportamiento. Agregar restricciones al modelo nos permitirá obtener modelos mejores y generar modelos con menos sesgo en sus decisiones. Recuerda, si podemos corregir el sesgo en un modelo, podremos tomar decisiones mejores en el futuro.\n",
    "\n",
    "El uso principal de esta restricción es indicar el comportamiento de una variable cuyo comportamiento conocemos a partir de conocimiento previo. Al establecer diferentes restricciones para cada variable, podemos generar modelos más precisos para el problema que queremos resolver y evitar problemas futuros con el modelo debido a una subrepresentación de los datos durante el entrenamiento. Por ejemplo: Supongamos que tenemos pocos datos para una variable $X_1$ que sabemos tiene un comportamiento monótonamente negativo con el objetivo Y. Sin embargo, el comportamiento en el conjunto de datos de entrenamiento nos muestra una historia diferente. Si observáramos la relación entre el objetivo y la característica, veríamos una tendencia monótonamente positiva. ¿Cómo podemos resolver esto?... mediante la imposición de restricciones de monotonía en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475972e6-994b-4e82-ae31-4cc2e924b60c",
   "metadata": {},
   "source": [
    "![image4](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915093309.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c84ff1-f824-4791-8928-d57216503c6d",
   "metadata": {},
   "source": [
    "¿Qué logramos al aplicar estas restricciones a nuestro modelo? Básicamente, resolvimos 3 puntos durante el modelado: Equidad, consistencia y confiabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63e9e2-8bc9-46f5-b7fe-71797e358ce4",
   "metadata": {},
   "source": [
    "![](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915095556.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef02125-2689-42d6-9193-8f0b3f421156",
   "metadata": {},
   "source": [
    "### Dependencias Parciales\n",
    "\n",
    "¿Qué es un Gráfico de Dependencias Parciales? Básicamente, es un gráfico que nos ayuda a comprender el comportamiento de una variable en relación con el objetivo. Estos gráficos nos permiten ver el comportamiento esperado (promedio) de la variable con respecto al objetivo y se representan como un gráfico de líneas donde X es la variable que deseamos analizar y Y es el objetivo.\n",
    "\n",
    "![Imagen 1](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915082448.png?raw=true)\n",
    "\n",
    "#### ¿Cómo se implementa esto?\n",
    "\n",
    "La función parcial $\\hat{f}_S$ se estima calculando promedios en los datos de entrenamiento, también conocido como método de Monte Carlo:\n",
    "\n",
    "$$\\hat{f}_S(x_S) = \\frac{1}{n} \\sum_{i=1}^n \\hat{f} (x_S, x_C^{(i)})$$\n",
    "\n",
    "La función parcial nos dice cuál es el efecto marginal promedio en la predicción para un valor dado (o valores) de las características S. En esta fórmula, $x_C^{(i)}$ son los valores reales de las características del conjunto de datos para las características en las que no estamos interesados, y n es el número de instancias en el conjunto de datos. Se asume en el PDP que las características en C no están correlacionadas con las características en S.\n",
    "\n",
    "#### ¿Por qué es relevante?\n",
    "\n",
    "Una comparación de gráficos de dependencias parciales puede proporcionar una visión importante, por ejemplo, revelar la estabilidad de la predicción del modelo. Algunas otras características que estos modelos permiten son:\n",
    "\n",
    "1. Se pueden crear perfiles para todas las observaciones en el conjunto, así como para la división en relación con otras variables. Por ejemplo, podemos ver cómo se comporta una variable específica cuando se diferencia por género, raza u otros factores.\n",
    "2. Podemos detectar algunas relaciones complicadas entre variables. Por ejemplo, tenemos perfiles de DP para dos modelos y podemos ver que uno de los modelos simples (regresión lineal) no detecta ninguna dependencia, mientras que el perfil de un modelo de caja negra (bosque aleatorio) nota una diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f38da0-be78-4a23-891e-55d6d0fbe936",
   "metadata": {},
   "source": [
    "### Restricciones de Interacción\n",
    "\n",
    "Otro problema que puede surgir en los modelos que generamos es la creación de modelos sesgados. Estos casos pueden ocurrir cuando observamos que las SHAPs en nuestro modelo relacionan variables que no deberían estar relacionadas, generando problemas de discriminación en el camino. Por ejemplo, la figura a continuación muestra cómo la raza interactúa más intensamente con la duración de la estancia, el grupo de edad y los antecedentes por año. Estas interacciones desaparecerían una vez que elimináramos la raza. Sin embargo, dada esta observación, se debe prestar especial atención si estas características no tienen sesgo racial incorporado. La investigación respalda la necesidad del grupo de edad y los antecedentes por año, lo que deja la duración de la estancia como candidata para un escrutinio.\n",
    "\n",
    "![Imagen 2](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915100939.png?raw=true)\n",
    "\n",
    "Cuando la profundidad del árbol es mayor que uno, muchas variables interactúan únicamente con el fin de minimizar la pérdida de entrenamiento, y el árbol de decisión resultante puede capturar una relación espuria (ruido) en lugar de una relación legítima que generalice en diferentes conjuntos de datos. Las **restricciones de interacción de características** permiten a los usuarios decidir qué variables pueden interactuar y cuáles no.\n",
    "\n",
    "Ajustando las restricciones de interacción en el conjunto de datos anterior y evitando la relación entre las variables raciales y el resto de los datos, podemos obtener los siguientes resultados.\n",
    "\n",
    "![Imagen 3](https://github.com/MDS7202/MDS7202/blob/main/recursos/2023-02/bosting/Pasted%20image%2020230915101644.png?raw=true)\n",
    "\n",
    "Los posibles beneficios incluyen:\n",
    "- Mejor rendimiento predictivo al centrarse en las interacciones que funcionan.\n",
    "- Menos ruido en las predicciones; mejor generalización.\n",
    "- Mayor control para el usuario sobre lo que el modelo puede ajustar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530eaec-3909-4516-a4ec-8e4738a84b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
