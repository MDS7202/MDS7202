{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e45e86",
   "metadata": {},
   "source": [
    "# Clase Extra 2 - Ensamblaje de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52573471",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ensamblaje de Modelos\n",
    "\n",
    "Es muy probable que para los problemas complejos, los clasificadores vistos anteriormente (KNN, Decision Trees, Bayes) no sean capaces de producir modelos lo suficientemente complejo como para resolverlos. \n",
    "\n",
    "Si bien el camino usual para resolver el problema de la complejidad es crear modelos de redes neuronales, estos por lo general requieren una gran cantidad de datos para generalizar correctamente. Por ende, si no se posee una mayor cantidad de datos, no siempre será la elección correcta.\n",
    "\n",
    "Una opción interesante para tener en cuenta es el de utilizar **ensamblaje de modelos**. \n",
    "\n",
    "Los modelos generados por ensamblaje no son otra variedad de modelos más complejos y distintos a los vistos anteriormente, si no que son frameworks para generar **meta-modelos**, que no son otra cosa que combinaciones de muchos modelos poco complejos y con poca precisión (*weak-learners*).\n",
    "La hipótesis principal de estos modelos es que la combinación de varios *weak-learners* poco precisos permite generar modelos mucho más complejos con la misma cantidad de datos.\n",
    "\n",
    "Los *weak learners* pueden ser entrenados con pocos datos y muy rápidamente; tal como caso de los árboles de decisión. \n",
    "La combinación de estos modelos poco complejos se hace a través de algún mecanismo de agregación/votación. \n",
    "\n",
    "\n",
    "\n",
    "Existen dos paradigmas de creación de modelos ensamblados: **Bagging y Boosting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd966f2",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap Aggregating)\n",
    "\n",
    "**Bagging** consiste en entrenar varios *weak learners* (ej, trees) usando distintos muestreos del dataset de entrenamiento y luego combinar los modelos entrenados.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='./resources/ensemble_bagging.png' width=800/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div align='center'>\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Bootstrap_aggregating'>Boosting en Wikipedia</a>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Un ejemplo clásico de este es `RandomForest`.\n",
    "Su funcionaimento es relativamente sencillo: \n",
    "\n",
    "Supongamos que se entrenarán $B$ ($B$ de bags) árboles de decisión y que cada arbol será entrenado con $n$ datos. Entonces,\n",
    "\n",
    "\n",
    "\n",
    "- Por cada $b=1,...B$:\n",
    "    - Obtenemos un subconjunto de entrenamiento con n elementos a través de un muestreo con reemplazo (*bootstrap*) sobre conjunto de entrenamiento original.\n",
    "    - Entrenamos un árbol de decisión para regresión o clasificación $f_b$ usando ese set.\n",
    "\n",
    "Luego, dado un ejemplo por predecir $x$, para obtener los valores de:\n",
    "\n",
    "- Una regresión se calcula: \n",
    "\n",
    "$$\\hat{y} = \\frac{1}{B}\\sum_{b=1}^{B}f_b(x)$$\n",
    "\n",
    "- Una clasificación, se retorna la clase con más votos. \n",
    "\n",
    "\n",
    "EL siguiente ejemplo consiste en un problema de detección de fraudes bancarios. \n",
    "Para mostrar el funcionamiento de Random Forest, evaluaremos la tarea anterior usando un modelo `DecisionTree` y compararemos el aumento de rendimiento usando luego un `RandomForest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395c9c5",
   "metadata": {},
   "source": [
    "## Credit Card Fraud\n",
    "\n",
    "El problema de esta clase consiste en, dados ciertos atributos preprocesados usando PCA (por lo que no sabemos que codifica cada dimensión), generar un clasificador que prediga si una fila representa o no un fraude bancario.\n",
    "\n",
    "La fuente de los datos la pueden encontrar en [creditcardfraud en Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d012f489",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./resources/creditcard.pickle')\n",
    "df = df.drop(columns=['Time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22856e",
   "metadata": {},
   "source": [
    "#### Desablance de Clases\n",
    "\n",
    "Una de las cosas que pueden notar de este dataset es un tremendo desbalance de clases: 284315 no fraudes vs 492 fraudes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db5fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise the amount column\n",
    "features = df.drop(columns=['Class']) \n",
    "labels = df['Class']\n",
    "# as you can see there are 492 fraud transactions.\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f6e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=labels,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b448f0",
   "metadata": {},
   "source": [
    "#### Pipeline con DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e23ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "\n",
      "[[85256    39]\n",
      " [   41   107]]\n",
      "\n",
      "Reporte de Clasificación\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.73      0.72      0.73       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.86      0.86     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# generar el pipeline\n",
    "pipe1 = Pipeline([('Preprocesamiento',\n",
    "                   ColumnTransformer([\n",
    "                       ('Scaler', StandardScaler(), ['Amount']),\n",
    "                   ],\n",
    "                                     remainder='passthrough')),\n",
    "                  ('Decision Tree', DecisionTreeClassifier(random_state=44))])\n",
    "\n",
    "# entrenar\n",
    "pipe1.fit(X_train, y_train.ravel())\n",
    "\n",
    "# predecir\n",
    "y_pred = pipe1.predict(X_test)\n",
    "\n",
    "# reporte de clasificación\n",
    "print('Matriz de confusión\\n')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nReporte de Clasificación\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b1a42",
   "metadata": {},
   "source": [
    "#### Pipeline Con RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20ae364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "\n",
      "[[85288     7]\n",
      " [   31   117]]\n",
      "\n",
      "Reporte de Clasificación\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.94      0.79      0.86       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.90      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generar el pipeline\n",
    "pipe2 = Pipeline(\n",
    "    [('Preprocesamiento', ColumnTransformer([\n",
    "        ('Scaler', StandardScaler() , ['Amount']),\n",
    "    ], remainder='passthrough')),\n",
    "     ('Random Forest', RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=44))\n",
    "    ])\n",
    "\n",
    "# entrenar\n",
    "pipe2.fit(X_train, y_train.ravel())\n",
    " \n",
    "# predecir\n",
    "y_pred = pipe2.predict(X_test)\n",
    "\n",
    "# reporte de clasificación\n",
    "print('Matriz de confusión\\n')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nReporte de Clasificación\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fbe9c",
   "metadata": {},
   "source": [
    "Como se puede ver, `RandomForest` incremento en la precisión y recall de la clase 1 con respecto al `DecisionTree`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086ea50",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "El segundo enfoque para crear modelos ensamblados es Boosting. En este caso, cada modelo se entrena con todos los datos, pero los modelos se entrenan de forma iterativa de tal forma que los modelos siguientes intentan corregir los errores de los modelos anteriores.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='./resources/ensemble_boosting.png' width=800/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div align='center'>\n",
    "    Fuente: <a href='https://en.wikipedia.org/wiki/Boosting_(machine_learning)'>Boosting en Wikipedia</a>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "La idea, en términos simples, es que los primeros modelos predigan bien los casos más generales, mientras que los modelos más profundos se encarguen de predecir los casos más particulares y dificiles.\n",
    "\n",
    "\n",
    "\n",
    "El modelo ensamblado final será una combinación de los modelos creados en el proceso iterativo. Uno de los algoritmos más populares para crear este tipo de modelos es `GradientBoosting` (usaremos `HistGradientBoostingClassifier`, una implementación mucho más rápida en el ejemplo). Una explicación de su idea principal viene a continuación.\n",
    "\n",
    "\n",
    "Dada $M$ iteraciones, el algoritmo para generar un modelo para regresión es:\n",
    "\n",
    "- Comenzamos con un modelo constante $f = f_0$\n",
    "- Luego, por cada label $i=1,\\dots,N$, la transformamos a $\\hat{y}_i \\leftarrow y_i - f(x_i)$. $\\hat{y}_i$ es llamado residual y su conjunto se transforma en las nuevas labels de $x$.\n",
    "- Ahora, entrenamos un nuevo modelo (tree) $f_1$ y redefinimos $f = f_0 + \\alpha f_1$. $\\alpha$ es conocido como learning rate.\n",
    "- Computamos nuevamente los residuales y calculamos un nuevo modelo $f_2$. Luego, fijamos el modelo predictivo como $f = f_0 + \\alpha f_1 + \\alpha f_2$.\n",
    "- Repetimos hasta que se cumplan $M$ iteraciones.\n",
    "\n",
    "\n",
    "La idea general es que en cada iteración los residuales más cercanos a 0 son los que se están clasificando correctamente mientras que los residuales con valores más altos son mal predichos se espera que se vayan corrigiendo en los modelos más profundos hasta alcanzar el modelo $M$.\n",
    "\n",
    "El caso de la clasificación es un poco más complejo y utiliza modelos de Regresión Logística para lograrlo. Queda propuesta su profundización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0062dff7",
   "metadata": {},
   "source": [
    "#### Pipeline con GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3d4477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "\n",
      "[[85286     9]\n",
      " [   33   115]]\n",
      "\n",
      "Reporte de Clasificación\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.93      0.78      0.85       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.96      0.89      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# generar el pipeline\n",
    "pipe3 = Pipeline(\n",
    "    [('Preprocesamiento', ColumnTransformer([\n",
    "        ('Scaler', StandardScaler() , ['Amount']),\n",
    "    ], remainder='passthrough')),\n",
    "     ('HistGradientBoostingClassifier', HistGradientBoostingClassifier(\n",
    "         random_state=44, \n",
    "         l2_regularization=10, \n",
    "         max_depth=15,\n",
    "         max_iter=1000))\n",
    "    ])\n",
    "\n",
    "# entrenar\n",
    "pipe3.fit(X_train, y_train.ravel())\n",
    " \n",
    "# predecir\n",
    "y_pred = pipe3.predict(X_test)\n",
    "\n",
    "# reporte de clasificación\n",
    "print('Matriz de confusión\\n')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nReporte de Clasificación\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecbfbd4",
   "metadata": {},
   "source": [
    "Nuevamente vemos mejores resultados en este tipo de clasificador con respecto al árbol básico. \n",
    "\n",
    "\n",
    "En general, Gradient Boosting puede ser más poderoso que los basados en bagging, pero si entrenamiento de caracter secuencial puede hacelo mucho más lento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae6000",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "\n",
    "- [1] The Hundred-Page Machine Learning Book, Andriy Burkov. Artículo 7.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
